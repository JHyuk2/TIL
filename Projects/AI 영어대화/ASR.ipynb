{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 라이브러리 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Collecting setuptools (from torch)\n",
      "  Downloading setuptools-75.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.0-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/203.0 MB 7.6 MB/s eta 0:00:27\n",
      "    --------------------------------------- 3.4/203.0 MB 7.7 MB/s eta 0:00:26\n",
      "    --------------------------------------- 4.2/203.0 MB 7.6 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 5.5/203.0 MB 6.5 MB/s eta 0:00:31\n",
      "   -- ------------------------------------- 11.8/203.0 MB 11.4 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 19.4/203.0 MB 15.5 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 29.1/203.0 MB 19.8 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 34.1/203.0 MB 20.6 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 42.7/203.0 MB 22.8 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 54.3/203.0 MB 26.0 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 61.3/203.0 MB 26.8 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 73.1/203.0 MB 29.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 85.5/203.0 MB 31.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 97.3/203.0 MB 33.2 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 103.8/203.0 MB 34.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 104.9/203.0 MB 31.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 107.0/203.0 MB 30.2 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 118.0/203.0 MB 31.4 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 126.1/203.0 MB 32.0 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 135.0/203.0 MB 32.3 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 144.2/203.0 MB 32.9 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 154.7/203.0 MB 33.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 166.5/203.0 MB 34.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 167.2/203.0 MB 33.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 175.1/203.0 MB 34.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 177.2/203.0 MB 33.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 185.9/203.0 MB 32.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 191.9/203.0 MB 33.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  201.3/203.0 MB 33.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 32.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 32.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 32.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 203.0/203.0 MB 30.2 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.2/6.2 MB 38.0 MB/s eta 0:00:00\n",
      "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 7.9/10.1 MB 40.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 37.1 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.5.0-cp38-abi3-win_amd64.whl (303 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 27.3 MB/s eta 0:00:00\n",
      "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 47.1 MB/s eta 0:00:00\n",
      "Downloading setuptools-75.7.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 31.0 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 18.3 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, setuptools, safetensors, regex, networkx, MarkupSafe, jinja2, torch, tokenizers, transformers\n",
      "Successfully installed MarkupSafe-3.0.2 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 regex-2024.11.6 safetensors-0.5.0 setuptools-75.7.0 sympy-1.13.1 tokenizers-0.21.0 torch-2.5.1 transformers-4.47.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\dm705\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.27.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (75.7.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.12.14)\n",
      "Downloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.2.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install librosa soundfile langchain sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.23.4\n",
      "  Downloading numpy-1.23.4.tar.gz (10.7 MB)\n",
      "     ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "     ------------- -------------------------- 3.7/10.7 MB 18.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 10.7/10.7 MB 27.9 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [33 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 112, in get_requires_for_build_wheel\n",
      "          backend = _build_backend()\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\n",
      "          obj = import_module(mod_path)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "          return _bootstrap._gcd_import(name[level:], package, level)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "        File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
      "        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "        File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "        File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "        File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Temp\\pip-build-env-9sl40yg2\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 16, in <module>\n",
      "          import setuptools.version\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Temp\\pip-build-env-9sl40yg2\\overlay\\Lib\\site-packages\\setuptools\\version.py\", line 1, in <module>\n",
      "          import pkg_resources\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Temp\\pip-build-env-9sl40yg2\\overlay\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 2172, in <module>\n",
      "          register_finder(pkgutil.ImpImporter, find_on_path)\n",
      "                          ^^^^^^^^^^^^^^^^^^^\n",
      "      AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "# !pip install numpy==1.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (3.11.11)\n",
      "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain)\n",
      "  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.2.10-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.0.2)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.47.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.6.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (0.27.0)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.29->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.13-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.7.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 23.3 MB/s eta 0:00:00\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Downloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
      "Downloading langchain_text_splitters-0.3.4-py3-none-any.whl (27 kB)\n",
      "Downloading langsmith-0.2.10-py3-none-any.whl (326 kB)\n",
      "Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 36.7 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 58.9 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 50.3 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.13-cp312-cp312-win_amd64.whl (135 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: tenacity, sniffio, pydantic-core, Pillow, orjson, jsonpointer, h11, greenlet, annotated-types, SQLAlchemy, requests-toolbelt, pydantic, jsonpatch, httpcore, anyio, httpx, langsmith, sentence-transformers, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed Pillow-11.1.0 SQLAlchemy-2.0.36 annotated-types-0.7.0 anyio-4.8.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.14 langchain-core-0.3.29 langchain-text-splitters-0.3.4 langsmith-0.2.10 orjson-3.10.13 pydantic-2.10.4 pydantic-core-2.27.2 requests-toolbelt-1.0.0 sentence-transformers-3.3.1 sniffio-1.3.1 tenacity-9.0.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. 모델 불러오기 및 파이프라인 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype,\n",
    "    # low_cpu_mem_usage=True, \n",
    "    use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': '0d38672e0bbdbdc460af55b8bb84a15b2730db2819f2af64f9c777d4d586f2de',\n",
       "  'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00024414, 0.00048828,\n",
       "         0.0005188 ]),\n",
       "  'sampling_rate': 16000}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You have passed more than 3000 mel input features (> 30 seconds) which automatically enables long-form generation which requires the model to predict timestamp tokens. Please either pass `return_timestamps=True` or make sure to pass no more than 3000 mel input features.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:283\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    224\u001b[0m     inputs: Union[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    226\u001b[0m ):\n\u001b[0;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m    documentation for more information.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\base.py:1293\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[1;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\base.py:1208\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1207\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1208\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1209\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:515\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline._forward\u001b[1;34m(self, model_inputs, return_timestamps, **generate_kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    513\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m--> 515\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;66;03m# whisper longform generation stores timestamps in \"segments\"\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_timestamps \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq2seq_whisper\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:536\u001b[0m, in \u001b[0;36mWhisperGenerationMixin.generate\u001b[1;34m(self, input_features, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, prompt_condition_type, condition_on_prev_tokens, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, num_segment_frames, attention_mask, time_precision, time_precision_features, return_token_timestamps, return_segments, return_dict_in_generate, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;66;03m# 3. Make sure generation config is correctly set\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;66;03m# Make sure the generation config is correctly set depending on whether timestamps are to be returned or not\u001b[39;00m\n\u001b[0;32m    530\u001b[0m return_dict_in_generate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_return_outputs(\n\u001b[0;32m    531\u001b[0m     return_dict_in_generate\u001b[38;5;241m=\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m    532\u001b[0m     return_token_timestamps\u001b[38;5;241m=\u001b[39mreturn_token_timestamps,\n\u001b[0;32m    533\u001b[0m     logprob_threshold\u001b[38;5;241m=\u001b[39mlogprob_threshold,\n\u001b[0;32m    534\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m    535\u001b[0m )\n\u001b[1;32m--> 536\u001b[0m timestamp_begin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_return_timestamps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_timestamps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_timestamps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_shortform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_shortform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_language_and_task(\n\u001b[0;32m    540\u001b[0m     language\u001b[38;5;241m=\u001b[39mlanguage, task\u001b[38;5;241m=\u001b[39mtask, is_multilingual\u001b[38;5;241m=\u001b[39mis_multilingual, generation_config\u001b[38;5;241m=\u001b[39mgeneration_config\n\u001b[0;32m    541\u001b[0m )\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_num_frames(\n\u001b[0;32m    543\u001b[0m     return_token_timestamps\u001b[38;5;241m=\u001b[39mreturn_token_timestamps, generation_config\u001b[38;5;241m=\u001b[39mgeneration_config, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[0;32m    544\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:1214\u001b[0m, in \u001b[0;36mWhisperGenerationMixin._set_return_timestamps\u001b[1;34m(self, return_timestamps, is_shortform, generation_config)\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_shortform:\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_timestamps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m-> 1214\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1215\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have passed more than 3000 mel input features (> 30 seconds) which automatically enables long-form generation which \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1216\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires the model to predict timestamp tokens. Please either pass `return_timestamps=True` or make sure to pass no more than 3000 mel input features.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1217\u001b[0m         )\n\u001b[0;32m   1219\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting `return_timestamps=True` for long-form generation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1220\u001b[0m     return_timestamps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: You have passed more than 3000 mel input features (> 30 seconds) which automatically enables long-form generation which requires the model to predict timestamp tokens. Please either pass `return_timestamps=True` or make sure to pass no more than 3000 mel input features."
     ]
    }
   ],
   "source": [
    "result = pipe(sample)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 오디오 파일 로드\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# audio = AudioSegment.from_file(\"path_to_audio_file.wav\")\u001b[39;00m\n\u001b[0;32m      5\u001b[0m audio \u001b[38;5;241m=\u001b[39m sample\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydub'"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# 오디오 파일 로드\n",
    "# audio = AudioSegment.from_file(\"path_to_audio_file.wav\")\n",
    "audio = sample\n",
    "\n",
    "# 30초 단위로 분할\n",
    "chunk_length_ms = 30 * 1000  # 30초\n",
    "chunks = [audio[i:i + chunk_length_ms] for i in range(0, len(audio), chunk_length_ms)]\n",
    "\n",
    "# 각 분할 저장\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.export(f\"chunk_{i}.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

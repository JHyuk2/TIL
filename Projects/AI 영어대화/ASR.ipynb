{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 라이브러리 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 설명\n",
    "\n",
    "- 오디오 처리: numpy, librosa, soundfile, pydub\n",
    "- 모델 실행: torch, transformers, accelerate\n",
    "- 응용 프로그램 구성: langchain, sentence-transformers\n",
    "- 데이터셋: datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설치한 라이브러리들 설명  \n",
    "\n",
    "### 핵심 AI 및 NLP 관련 라이브러리\n",
    "1. `torch`  \n",
    "PyTorch는 딥러닝 모델을 구축하고 훈련하는 데 사용하는 오픈소스 라이브러리입니다.  \n",
    "GPU 가속을 지원하며, 특히 자연어 처리와 컴퓨터 비전에서 널리 사용됩니다.  \n",
    "Transformers 모델을 실행하거나 커스텀 모델을 훈련할 때 사용됩니다.  \n",
    "\n",
    "2. `transformers`  \n",
    "Hugging Face에서 제공하는 라이브러리로, 사전 학습된 NLP 모델(BERT, GPT, Whisper 등)을 쉽게 사용할 수 있습니다.  \n",
    "Whisper 모델도 이 라이브러리를 통해 로드하여 사용합니다.  \n",
    "Whisper 모델로 음성 데이터를 텍스트로 변환하는 데 사용됩니다.  \n",
    "\n",
    "3. `accelerate`  \n",
    "Hugging Face에서 제공하는 라이브러리로, 모델 훈련과 추론을 가속화하고 여러 디바이스(CPU, GPU, TPU 등)를 활용하도록 지원합니다.  \n",
    "Whisper나 기타 Transformer 기반 모델을 실행 시 성능 최적화에 사용됩니다.  \n",
    "\n",
    "4. `langchain`  \n",
    "대규모 언어 모델(LLM)을 활용한 애플리케이션을 구축하는 프레임워크입니다.  \n",
    "여러 NLP 작업(질의응답, 대화 생성 등)을 연결하는 워크플로우를 구성할 때 사용됩니다.  \n",
    "LLM 기반 애플리케이션 개발에 사용됩니다. Whisper와 결합하여 음성 인식 후 처리 로직을 작성할 때 유용할 수 있습니다.  \n",
    "\n",
    "1. `sentence-transformers`  \n",
    "문장 수준의 임베딩(벡터 표현)을 생성하는 데 사용되는 라이브러리입니다.  \n",
    "텍스트 데이터의 유사도 측정이나 검색 작업에 널리 사용됩니다.  \n",
    "Whisper로 변환된 텍스트 데이터를 처리하거나 분석하는 데 사용될 수 있습니다.  \n",
    "\n",
    "\n",
    "### 오디오 처리 및 데이터 관련 라이브러리  \n",
    "1. `numpy==1.23.4`  \n",
    "Python의 대표적인 수치 계산 라이브러리로, 행렬 연산 및 고성능 배열 처리를 지원합니다.  \n",
    "Whisper 모델 및 오디오 데이터 처리에서 핵심적인 역할을 합니다.  \n",
    "PCM 데이터를 처리하거나 librosa와 함께 오디오 데이터 배열을 조작할 때 사용됩니다.  \n",
    "(`librosa`와 호환하기 위해 버전을 지정해주었습니다. 2.0.0 버전도 가능)  \n",
    "\n",
    "2. `librosa`  \n",
    "오디오 분석과 신호 처리를 위한 라이브러리입니다.  \n",
    "오디오 데이터를 주파수 영역(Mel Spectrogram)으로 변환하는 등 Whisper 모델과 직접적으로 연관이 있습니다.  \n",
    "Whisper 모델에 입력으로 제공되는 데이터를 전처리하거나 변환하는 데 사용됩니다.  \n",
    "\n",
    "3. `soundfile`  \n",
    "오디오 파일을 읽고 쓰는 데 사용되는 라이브러리입니다.  \n",
    "`librosa`가 내부적으로 의존합니다.  \n",
    "오디오 데이터를 로드하거나 저장할 때 사용됩니다.  \n",
    "\n",
    "4. `pydub`  \n",
    "오디오 데이터를 자르거나 합치는 등의 작업을 지원하는 라이브러리입니다.  \n",
    "ffmpeg와 함께 동작하며, Whisper에 입력으로 제공할 오디오를 준비하는 데 유용합니다.  \n",
    "긴 오디오 데이터를 30초 단위로 분할하거나 특정 포맷으로 변환할 때 사용됩니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (4.47.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (1.2.1)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from accelerate) (6.1.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from langchain) (3.11.11)\n",
      "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain)\n",
      "  Using cached langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.2.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.6.0-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.15.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.29->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.13-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
      "Using cached langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
      "Using cached sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Using cached langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
      "Using cached langchain_text_splitters-0.3.4-py3-none-any.whl (27 kB)\n",
      "Using cached langsmith-0.2.10-py3-none-any.whl (326 kB)\n",
      "Using cached pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached scikit_learn-1.6.0-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Using cached scipy-1.15.0-cp312-cp312-win_amd64.whl (43.6 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached orjson-3.10.13-cp312-cp312-win_amd64.whl (135 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, tenacity, scipy, pydantic-core, Pillow, orjson, jsonpatch, joblib, greenlet, annotated-types, SQLAlchemy, scikit-learn, requests-toolbelt, pydantic, langsmith, langchain-core, sentence-transformers, langchain-text-splitters, langchain\n",
      "Successfully installed Pillow-11.1.0 SQLAlchemy-2.0.36 annotated-types-0.7.0 greenlet-3.1.1 joblib-1.4.2 jsonpatch-1.33 langchain-0.3.14 langchain-core-0.3.29 langchain-text-splitters-0.3.4 langsmith-0.2.10 orjson-3.10.13 pydantic-2.10.4 pydantic-core-2.27.2 requests-toolbelt-1.0.0 scikit-learn-1.6.0 scipy-1.15.0 sentence-transformers-3.3.1 tenacity-9.0.0 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch transformers accelerate langchain sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.23.4\n",
      "  Using cached numpy-1.23.4.tar.gz (10.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [33 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_\\xec쁺\\xec뼱\\xeb\\x8c\\x80\\xed솕-UlUCYZce-py3.12\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_\\xec쁺\\xec뼱\\xeb\\x8c\\x80\\xed솕-UlUCYZce-py3.12\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_\\xec쁺\\xec뼱\\xeb\\x8c\\x80\\xed솕-UlUCYZce-py3.12\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 112, in get_requires_for_build_wheel\n",
      "          backend = _build_backend()\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_\\xec쁺\\xec뼱\\xeb\\x8c\\x80\\xed솕-UlUCYZce-py3.12\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\n",
      "          obj = import_module(mod_path)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "          return _bootstrap._gcd_import(name[level:], package, level)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "        File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
      "        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "        File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "        File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "        File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Temp\\pip-build-env-4nq6pjul\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 16, in <module>\n",
      "          import setuptools.version\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Temp\\pip-build-env-4nq6pjul\\overlay\\Lib\\site-packages\\setuptools\\version.py\", line 1, in <module>\n",
      "          import pkg_resources\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Temp\\pip-build-env-4nq6pjul\\overlay\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 2172, in <module>\n",
      "          register_finder(pkgutil.ImpImporter, find_on_path)\n",
      "                          ^^^^^^^^^^^^^^^^^^^\n",
      "      AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "# !pip install numpy==1.23.4 librosa soundfile pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Using cached librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from librosa) (2.0.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from librosa) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Using cached numba-0.60.0-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Using cached soundfile-0.13.0-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Using cached soxr-0.5.0.post1-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Collecting lazy-loader>=0.1 (from librosa)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Using cached msgpack-1.1.0-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Using cached llvmlite-0.43.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.12.14)\n",
      "Using cached librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached msgpack-1.1.0-cp312-cp312-win_amd64.whl (75 kB)\n",
      "Using cached numba-0.60.0-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached soundfile-0.13.0-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Using cached soxr-0.5.0.post1-cp312-abi3-win_amd64.whl (164 kB)\n",
      "Using cached llvmlite-0.43.0-cp312-cp312-win_amd64.whl (28.1 MB)\n",
      "Installing collected packages: soxr, msgpack, llvmlite, lazy-loader, audioread, soundfile, pooch, numba, librosa\n",
      "Successfully installed audioread-3.0.1 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.43.0 msgpack-1.1.0 numba-0.60.0 pooch-1.8.2 soundfile-0.13.0 soxr-0.5.0.post1\n"
     ]
    }
   ],
   "source": [
    "# !pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. 모델 불러오기 및 파이프라인 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype,\n",
    "    # low_cpu_mem_usage=True, \n",
    "    use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터셋 활용\n",
    "- datasets / distil-whisper/librispeech_long\n",
    "  - 허깅페이스에서 제공하는 음성 데이터셋으로, 주로 ASR평가를 위해 사용\n",
    "  - 데이터 샘플\n",
    "  \n",
    "  ```python\n",
    "  {\n",
    "    \"audio\": {\n",
    "        \"path\": \"파일 경로 또는 파일 ID\",\n",
    "        \"array\": array([...]),  # PCM 데이터 배열\n",
    "        \"sampling_rate\": 16000  # 샘플링 속도\n",
    "    }\n",
    "  }\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': '0d38672e0bbdbdc460af55b8bb84a15b2730db2819f2af64f9c777d4d586f2de',\n",
       "  'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00024414, 0.00048828,\n",
       "         0.0005188 ]),\n",
       "  'sampling_rate': 16000}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[0]['audio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 데이터셋 변환 (PCM -> pydub.AudioSegment)\n",
    "- PCM(`Pulse Code Modulation`): 디지털 오디오 데이터의 기본 형식  \n",
    "\n",
    "- **특징**\n",
    "  - 1. 비압축 데이터\n",
    "    - 압축 코덱(MP3, AAC)과 달리 압축되지 않은 원시의 데이터\n",
    "  - 2. 샘플링\n",
    "    - 아날로그 오디오 신호를 일정한 간격으로 측정하여 디지털 값으로 변환\n",
    "  - 3. 샘플 폭\n",
    "    - PCM이 차지하는 비트 수를 나타내는데, 16비트, 8비트 같은 게 있음.\n",
    "  - 4. 채널\n",
    "    - 오디오가 모노(1채널)인지, 스테레오(2채널)인지 결정.\n",
    "\n",
    "- **장단점**\n",
    "  - 장점\n",
    "    - 1. 고품질 데이터\n",
    "      - 압축되지 않은 원본 데이터를 제공하므로, 품질 손실이 없음\n",
    "    - 2. 표준화\n",
    "      - 오디오 처리 라이브러리나 딥러닝 모델에서 기본적으로 사용 가능\n",
    "  - 단점\n",
    "    - 1. 큰 파일 크기\n",
    "      - 압축되지 않았기에 크기가 큼\n",
    "    - 2. 직접 사용에 불편\n",
    "      - 사람이 바로 이해하거나 사용 불가능한 형태로, 추가 처리가 필요함.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플 데이터를 짧게 보면\n",
    "\n",
    "```python\n",
    "{\n",
    "    'audio':{\n",
    "        'path': \"파일 경로 또는 파일 ID\",\n",
    "        'array' : [0.0023, 0.0035, -0.0046, ...], #PCM 데이터 배열\n",
    "        'sampling_rate' : 16000, # 샘플링 속도 (16,000Hz)\n",
    "        'channels' : 1, # 모노(1채널)\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '0d38672e0bbdbdc460af55b8bb84a15b2730db2819f2af64f9c777d4d586f2de',\n",
       " 'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00024414, 0.00048828,\n",
       "        0.0005188 ]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_0.wav 저장 완료\n",
      "chunk_1.wav 저장 완료\n",
      "chunk_2.wav 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# 오디오 파일 로드\n",
    "\n",
    "# 오디오 데이터 추출 및 AudioSegment 변환\n",
    "audio_array = sample['array']\n",
    "sampling_rate = sample['sampling_rate']\n",
    "\n",
    "# PCM 데이터를 16비트 정수로 변환\n",
    "audio_data = np.array(audio_array * 32767, dtype=np.int16)\n",
    "\n",
    "# AudioSegment로 변환\n",
    "audio = AudioSegment(\n",
    "    audio_data.tobytes(),\n",
    "    frame_rate=sampling_rate,\n",
    "    sample_width=audio_data.dtype.itemsize,\n",
    "    channels=1\n",
    ")\n",
    "\n",
    "# 오디오 분할 (30초 단위)\n",
    "chunk_length_ms = 30 * 1000  # 30초\n",
    "chunks = [audio[i:i + chunk_length_ms] for i in range(0, len(audio), chunk_length_ms)]\n",
    "\n",
    "# 각 분할 저장\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.export(f\"chunk_{i}.wav\", format=\"wav\")\n",
    "    print(f\"chunk_{i}.wav 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pydub.audio_segment.AudioSegment at 0x152742ed100>,\n",
       " <pydub.audio_segment.AudioSegment at 0x152742ee780>,\n",
       " <pydub.audio_segment.AudioSegment at 0x152742ef950>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 임시 파일 경로: C:\\Users\\dm705\\AppData\\Local\\Temp\n"
     ]
    }
   ],
   "source": [
    "from pydub.playback import play\n",
    "play(chunk[0])  # 이런 식으로 재생 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_영어대화-UlUCYZce-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

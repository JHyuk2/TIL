{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 라이브러리 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 설명\n",
    "\n",
    "- 오디오 처리: numpy, librosa, soundfile, pydub\n",
    "- 모델 실행: torch, transformers, accelerate\n",
    "- 응용 프로그램 구성: langchain, sentence-transformers\n",
    "- 데이터셋: datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설치한 라이브러리들 설명  \n",
    "\n",
    "### 핵심 AI 및 NLP 관련 라이브러리\n",
    "1. `torch`  \n",
    "PyTorch는 딥러닝 모델을 구축하고 훈련하는 데 사용하는 오픈소스 라이브러리입니다.  \n",
    "GPU 가속을 지원하며, 특히 자연어 처리와 컴퓨터 비전에서 널리 사용됩니다.  \n",
    "Transformers 모델을 실행하거나 커스텀 모델을 훈련할 때 사용됩니다.  \n",
    "\n",
    "2. `transformers`  \n",
    "Hugging Face에서 제공하는 라이브러리로, 사전 학습된 NLP 모델(BERT, GPT, Whisper 등)을 쉽게 사용할 수 있습니다.  \n",
    "Whisper 모델도 이 라이브러리를 통해 로드하여 사용합니다.  \n",
    "Whisper 모델로 음성 데이터를 텍스트로 변환하는 데 사용됩니다.  \n",
    "\n",
    "3. `accelerate`  \n",
    "Hugging Face에서 제공하는 라이브러리로, 모델 훈련과 추론을 가속화하고 여러 디바이스(CPU, GPU, TPU 등)를 활용하도록 지원합니다.  \n",
    "Whisper나 기타 Transformer 기반 모델을 실행 시 성능 최적화에 사용됩니다.  \n",
    "\n",
    "4. `langchain`  \n",
    "대규모 언어 모델(LLM)을 활용한 애플리케이션을 구축하는 프레임워크입니다.  \n",
    "여러 NLP 작업(질의응답, 대화 생성 등)을 연결하는 워크플로우를 구성할 때 사용됩니다.  \n",
    "LLM 기반 애플리케이션 개발에 사용됩니다. Whisper와 결합하여 음성 인식 후 처리 로직을 작성할 때 유용할 수 있습니다.  \n",
    "\n",
    "1. `sentence-transformers`  \n",
    "문장 수준의 임베딩(벡터 표현)을 생성하는 데 사용되는 라이브러리입니다.  \n",
    "텍스트 데이터의 유사도 측정이나 검색 작업에 널리 사용됩니다.  \n",
    "Whisper로 변환된 텍스트 데이터를 처리하거나 분석하는 데 사용될 수 있습니다.  \n",
    "\n",
    "\n",
    "### 오디오 처리 및 데이터 관련 라이브러리  \n",
    "1. `numpy==1.23.4`  \n",
    "Python의 대표적인 수치 계산 라이브러리로, 행렬 연산 및 고성능 배열 처리를 지원합니다.  \n",
    "Whisper 모델 및 오디오 데이터 처리에서 핵심적인 역할을 합니다.  \n",
    "PCM 데이터를 처리하거나 librosa와 함께 오디오 데이터 배열을 조작할 때 사용됩니다.  \n",
    "(`librosa`와 호환하기 위해 버전을 지정해주었습니다. 2.0.0 버전도 가능)  \n",
    "\n",
    "2. `librosa`  \n",
    "오디오 분석과 신호 처리를 위한 라이브러리입니다.  \n",
    "오디오 데이터를 주파수 영역(Mel Spectrogram)으로 변환하는 등 Whisper 모델과 직접적으로 연관이 있습니다.  \n",
    "Whisper 모델에 입력으로 제공되는 데이터를 전처리하거나 변환하는 데 사용됩니다.  \n",
    "\n",
    "3. `soundfile`  \n",
    "오디오 파일을 읽고 쓰는 데 사용되는 라이브러리입니다.  \n",
    "`librosa`가 내부적으로 의존합니다.  \n",
    "오디오 데이터를 로드하거나 저장할 때 사용됩니다.  \n",
    "\n",
    "4. `pydub`  \n",
    "오디오 데이터를 자르거나 합치는 등의 작업을 지원하는 라이브러리입니다.  \n",
    "ffmpeg와 함께 동작하며, Whisper에 입력으로 제공할 오디오를 준비하는 데 유용합니다.  \n",
    "긴 오디오 데이터를 30초 단위로 분할하거나 특정 포맷으로 변환할 때 사용됩니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch transformers accelerate langchain sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy==1.23.4 librosa soundfile pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 및 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': '0d38672e0bbdbdc460af55b8bb84a15b2730db2819f2af64f9c777d4d586f2de',\n",
       "  'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00024414, 0.00048828,\n",
       "         0.0005188 ]),\n",
       "  'sampling_rate': 16000}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. 데이터셋 활용\n",
    "- datasets / distil-whisper/librispeech_long\n",
    "  - 허깅페이스에서 제공하는 음성 데이터셋으로, 주로 ASR평가를 위해 사용\n",
    "  - 데이터 샘플\n",
    "  \n",
    "  ```python\n",
    "  {\n",
    "    \"audio\": {\n",
    "        \"path\": \"파일 경로 또는 파일 ID\",\n",
    "        \"array\": array([...]),  # PCM 데이터 배열\n",
    "        \"sampling_rate\": 16000  # 샘플링 속도\n",
    "    }\n",
    "  }\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[0]['audio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. 데이터셋 변환 (PCM -> pydub.AudioSegment)\n",
    "- PCM(`Pulse Code Modulation`): 디지털 오디오 데이터의 기본 형식  \n",
    "\n",
    "- **특징**\n",
    "  - 1. 비압축 데이터\n",
    "    - 압축 코덱(MP3, AAC)과 달리 압축되지 않은 원시의 데이터\n",
    "  - 2. 샘플링\n",
    "    - 아날로그 오디오 신호를 일정한 간격으로 측정하여 디지털 값으로 변환\n",
    "  - 3. 샘플 폭\n",
    "    - PCM이 차지하는 비트 수를 나타내는데, 16비트, 8비트 같은 게 있음.\n",
    "  - 4. 채널\n",
    "    - 오디오가 모노(1채널)인지, 스테레오(2채널)인지 결정.\n",
    "\n",
    "- **장단점**\n",
    "  - 장점\n",
    "    - 1. 고품질 데이터\n",
    "      - 압축되지 않은 원본 데이터를 제공하므로, 품질 손실이 없음\n",
    "    - 2. 표준화\n",
    "      - 오디오 처리 라이브러리나 딥러닝 모델에서 기본적으로 사용 가능\n",
    "  - 단점\n",
    "    - 1. 큰 파일 크기\n",
    "      - 압축되지 않았기에 크기가 큼\n",
    "    - 2. 직접 사용에 불편\n",
    "      - 사람이 바로 이해하거나 사용 불가능한 형태로, 추가 처리가 필요함.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플 데이터를 짧게 보면\n",
    "\n",
    "```python\n",
    "{\n",
    "    'audio':{\n",
    "        'path': \"파일 경로 또는 파일 ID\",\n",
    "        'array' : [0.0023, 0.0035, -0.0046, ...], #PCM 데이터 배열\n",
    "        'sampling_rate' : 16000, # 샘플링 속도 (16,000Hz)\n",
    "        'channels' : 1, # 모노(1채널)\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '0d38672e0bbdbdc460af55b8bb84a15b2730db2819f2af64f9c777d4d586f2de',\n",
       " 'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00024414, 0.00048828,\n",
       "        0.0005188 ]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_0.wav 저장 완료\n",
      "chunk_1.wav 저장 완료\n",
      "chunk_2.wav 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# 오디오 파일 로드\n",
    "\n",
    "# 오디오 데이터 추출 및 AudioSegment 변환\n",
    "audio_array = sample['array']\n",
    "sampling_rate = sample['sampling_rate']\n",
    "\n",
    "# PCM 데이터를 16비트 정수로 변환\n",
    "audio_data = np.array(audio_array * 32767, dtype=np.int16)\n",
    "\n",
    "# AudioSegment로 변환\n",
    "audio = AudioSegment(\n",
    "    audio_data.tobytes(),\n",
    "    frame_rate=sampling_rate,\n",
    "    sample_width=audio_data.dtype.itemsize,\n",
    "    channels=1\n",
    ")\n",
    "\n",
    "# 오디오 분할 (30초 단위)\n",
    "chunk_length_ms = 30 * 1000  # 30초\n",
    "chunks = [audio[i:i + chunk_length_ms] for i in range(0, len(audio), chunk_length_ms)]\n",
    "\n",
    "# 각 분할 저장\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.export(f\"chunk_{i}.wav\", format=\"wav\")\n",
    "    print(f\"chunk_{i}.wav 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pydub.audio_segment.AudioSegment at 0x1dd629afd40>,\n",
       " <pydub.audio_segment.AudioSegment at 0x1dd3b6a8200>,\n",
       " <pydub.audio_segment.AudioSegment at 0x1dd3b7a3860>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 불러오기 및 파이프라인 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (float) and bias type (struct c10::Half) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 33\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# 신규 버전 업데이트) 기존 튜플을 EncoderDecoderCache로 변환\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# past_key_values = EncoderDecoderCache.from_legacy_cache(past_key_values)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(input_features)  \u001b[38;5;66;03m# 모든 입력이 활성화된 상태로 설정\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m generates_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 다양성\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# beam search를 사용한 텍스트 생성\u001b[39;49;00m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 기본값 1, 긴 텍스트에 조금 더 유리하도록 설정\u001b[39;49;00m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 입력 데이터에 대해 명시적으로 attention_mask 생성 후 전달\u001b[39;49;00m\n\u001b[0;32m     39\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m transcription \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mbatch_decode(generates_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:558\u001b[0m, in \u001b[0;36mWhisperGenerationMixin.generate\u001b[1;34m(self, input_features, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, prompt_condition_type, condition_on_prev_tokens, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, num_segment_frames, attention_mask, time_precision, time_precision_features, return_token_timestamps, return_segments, return_dict_in_generate, **kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_prompt_condition_type(\n\u001b[0;32m    553\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m    554\u001b[0m     prompt_condition_type\u001b[38;5;241m=\u001b[39mprompt_condition_type,\n\u001b[0;32m    555\u001b[0m )\n\u001b[0;32m    557\u001b[0m \u001b[38;5;66;03m# pass self.config for backward compatibility\u001b[39;00m\n\u001b[1;32m--> 558\u001b[0m init_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve_init_tokens\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_segment_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_segment_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;66;03m# passing `decoder_input_ids` is deprecated - the only exception is for assisted generation\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m# where the input ids are handled explicitly by the generate method\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_decoder_input_ids(kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:1377\u001b[0m, in \u001b[0;36mWhisperGenerationMixin._retrieve_init_tokens\u001b[1;34m(self, input_features, batch_size, generation_config, config, num_segment_frames, kwargs)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     lang_ids \u001b[38;5;241m=\u001b[39m [language_to_id(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m languages]\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(generation_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlang_to_id\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_lang_id_undefined:\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;66;03m# language is not defined or intentially set to `None` to trigger language detection\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m     lang_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_language\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoder_outputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_segment_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_segment_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lang_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1384\u001b[0m     \u001b[38;5;66;03m# append or replace lang_ids to init_tokens\u001b[39;00m\n\u001b[0;32m   1385\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(init_tokens)):\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:1481\u001b[0m, in \u001b[0;36mWhisperGenerationMixin.detect_language\u001b[1;34m(self, input_features, encoder_outputs, generation_config, num_segment_frames)\u001b[0m\n\u001b[0;32m   1475\u001b[0m decoder_input_ids \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1476\u001b[0m     torch\u001b[38;5;241m.\u001b[39mones((batch_size, \u001b[38;5;241m1\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m   1477\u001b[0m     \u001b[38;5;241m*\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1478\u001b[0m )\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m-> 1481\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1483\u001b[0m non_lang_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(logits[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[0;32m   1484\u001b[0m non_lang_mask[\u001b[38;5;28mlist\u001b[39m(generation_config\u001b[38;5;241m.\u001b[39mlang_to_id\u001b[38;5;241m.\u001b[39mvalues())] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:1767\u001b[0m, in \u001b[0;36mWhisperForConditionalGeneration.forward\u001b[1;34m(self, input_features, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, decoder_inputs_embeds, decoder_position_ids, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1763\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1764\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1765\u001b[0m         )\n\u001b[1;32m-> 1767\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1768\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_position_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_position_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1784\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1785\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_out(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1787\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:1618\u001b[0m, in \u001b[0;36mWhisperModel.forward\u001b[1;34m(self, input_features, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, decoder_inputs_embeds, decoder_position_ids, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1616\u001b[0m     input_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_input_features(input_features, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[1;32m-> 1618\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:1027\u001b[0m, in \u001b[0;36mWhisperEncoder.forward\u001b[1;34m(self, input_features, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1023\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1024\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[0;32m   1025\u001b[0m )\n\u001b[0;32m   1026\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1027\u001b[0m inputs_embeds \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mgelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1028\u001b[0m inputs_embeds \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mgelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(inputs_embeds))\n\u001b[0;32m   1030\u001b[0m inputs_embeds \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[0;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    369\u001b[0m     )\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (float) and bias type (struct c10::Half) should be the same"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# from transformers.models.whisper import EncoderDecoderCache\n",
    "\n",
    "# CUDA 사용\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# Whisper 모델 로드\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch_dtype,\n",
    "    # low_cpu_mem_usage=True, \n",
    "    use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# PCM 데이터를 Mel Spectorgram으로 변환 후 진행\n",
    "processor = AutoProcessor.from_pretrained(\"openai/whisper-large-v3-turbo\") # PCM -> Mel Spectrogram 입력 변환을 위함\n",
    "\n",
    "input_features = processor(\n",
    "    audio_array,\n",
    "    sampling_rate=sampling_rate,\n",
    "    return_tensors=\"pt\",\n",
    ").input_features\n",
    "\n",
    "\n",
    "# 신규 버전 업데이트) 기존 튜플을 EncoderDecoderCache로 변환\n",
    "# past_key_values = EncoderDecoderCache.from_legacy_cache(past_key_values)\n",
    "attention_mask = torch.ones_like(input_features)  # 모든 입력이 활성화된 상태로 설정\n",
    "\n",
    "generates_ids = model.generate(\n",
    "    input_features,\n",
    "    temperature=0.7, # 다양성\n",
    "    num_beams=2, # beam search를 사용한 텍스트 생성\n",
    "    length_penalty=1.3, # 기본값 1, 긴 텍스트에 조금 더 유리하도록 설정\n",
    "    attention_mask=attention_mask, # 입력 데이터에 대해 명시적으로 attention_mask 생성 후 전달\n",
    ")\n",
    "transcription = processor.batch_decode(generates_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: [\" Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind.\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"Transcription:\", transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 녹음한 파일로 ASR 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dm705\\\\Study\\\\TIL\\\\Projects\\\\AI 영어대화'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 존재 여부: True\n"
     ]
    }
   ],
   "source": [
    "file_name = 'self_motivation.m4a'\n",
    "file_path = os.path.join(os.getcwd(), file_name)\n",
    "print(\"파일 존재 여부:\", os.path.exists(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAV 변환 성공\n"
     ]
    }
   ],
   "source": [
    "# 이미 만들어진 processor, model을 사용\n",
    "\n",
    "'''\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch_dtype,\n",
    "    # low_cpu_mem_usage=True, \n",
    "    use_safetensors=True\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"openai/whisper-large-v3-turbo\") # PCM -> Mel Spectrogram 입력 변환을 위함\n",
    "'''\n",
    "\n",
    "# Whisper모델은 PCM데이터 or WAV형식 데이터를 필요로 하기 때문에, 변환해줌.\n",
    "import traceback # 전체 오류 스택 트레이스\n",
    "\n",
    "# load file\n",
    "try:\n",
    "    record_file = AudioSegment.from_file(file_path, format=\"m4a\")\n",
    "    # convert to WAV format\n",
    "    record_file.export(\"self_motivation.wav\", format='wav')\n",
    "    print(\"WAV 변환 성공\")\n",
    "except Exception as e:\n",
    "    print(\"오디오 변환 실패:\", e)\n",
    "    traceback.print_exc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FileNotFoundError가 발생하는 경우  \n",
    "> traceback.print_exc() 를 사용해서, 전체 오류 스택 트레이스를 출력할 수 있다.    \n",
    "> 나의 경우 `pydub`이 내부적으로 사용하는 `FFmpeg`가 설치되지 않아서 오류가 발생하는 것 같았음.  \n",
    "> - `Couldn't find ffprobe or avprobe` warning이 발생했기 때문.  \n",
    "> 때문에 `FFmpeg`를 아래와 같이 설치해줌.\n",
    "\n",
    "---\n",
    "#### 1. FFmpeg 다운로드\n",
    "- [FFmpeg 공식 웹사이트 접속](https://ffmpeg.org/download.html)\n",
    "- Windows 빌드 섹션에서 \"Windows builds by gyan.dev\" 링크 클릭.\n",
    "#### 2. Windows 빌드 다운로드\n",
    "- `ffmpeg-git-full.7z` 파일 다운로드\n",
    "#### 3. 압축 해제 후 환경변수 설정\n",
    "- 압축한 폴더의 `ffmpeg-bin` 폴더로 가서, 환경변수(시스템변수)로 추가.\n",
    "- bash창을 다시 닫고 아래의 명령어 실행\n",
    "- ```bash\n",
    "    ffmpeg -version  \n",
    "    ffprobe -version\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAV 변환 성공\n"
     ]
    }
   ],
   "source": [
    "# 재도전\n",
    "\n",
    "# load file\n",
    "try:\n",
    "    record_file = AudioSegment.from_file(file_path, format=\"m4a\")\n",
    "    # convert to WAV format\n",
    "    record_file.export(\"self_motivation.wav\", format='wav')\n",
    "    print(\"WAV 변환 성공\")\n",
    "except Exception as e:\n",
    "    print(\"오디오 변환 실패:\", e)\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오디오 데이터 길이: 492203\n",
      "샘플링 속도: 16000 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dm705\\AppData\\Local\\Temp\\ipykernel_11336\\1433415770.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sampling_rate = librosa.load(file_path, sr=16000)\n",
      "c:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "# librosa를 이용한 파일 읽기\n",
    "audio, sampling_rate = librosa.load(file_path, sr=16000)\n",
    "\n",
    "print(f'오디오 데이터 길이: {len(audio)}')\n",
    "print(f'샘플링 속도: {sampling_rate} Hz')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1) 기본 파라미터로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:   어떤 작업이든 지금부터 25분 동안 집중을 하고 5분 동안 휴식을 갖겠습니다. 앞으로 뽀모도로 기법을 활용해서 나의 하루를 바꿔나갈 것입니다. 나는 천재다. 나는 할 수 있다. 나는 좋은 일이 많이 생긴다. 나는 내가 원하는 모든 일을 이룰 수 있는 힘을 갖고 있다. 나는 준비가 되었고 나는 실행할 힘이 있다.\n"
     ]
    }
   ],
   "source": [
    "input_features = processor(\n",
    "    audio,\n",
    "    sampling_rate=16000,\n",
    "    return_tensors='pt'\n",
    ").input_features\n",
    "\n",
    "generates_ids = model.generate(input_features)\n",
    "transcription = processor.batch_decode(generates_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"Transcription: \", transcription[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) 하이퍼파라미터 튜닝 및 어텐션 마스크 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:   어떤 작업이든 지금부터 25분 동안 집중을 하고 5분 동안 휴식을 갖겠습니다. 앞으로 뽀모도로 기법을 활용해서 나의 하루를 바꿔나갈 것입니다. 나는 천재다. 나는 할 수 있다. 나는 좋은 일이 많이 생긴다. 나는 내가 원하는 모든 일을 이룰 수 있는 힘을 갖고 있다. 나는 준비가 되었고 나는 실행할 힘이 있다.\n"
     ]
    }
   ],
   "source": [
    "attention_mask = torch.ones_like(input_features)  # 모든 입력이 활성화된 상태로 설정\n",
    "\n",
    "generates_ids = model.generate(\n",
    "    input_features,\n",
    "    temperature=0.7, # 다양성\n",
    "    length_penalty=1.3, # 기본값 1, 긴 텍스트에 조금 더 유리하도록 설정\n",
    "    attention_mask=attention_mask, # 입력 데이터에 대해 명시적으로 attention_mask 생성 후 전달\n",
    ")\n",
    "transcription = processor.batch_decode(generates_ids, skip_special_tokens=True)\n",
    "print(\"Transcription: \", transcription[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (2.5.1)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.1%2Bcu118-cp312-cp312-win_amd64.whl (5.3 MB)\n",
      "     ---------------------------------------- 0.0/5.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 5.3/5.3 MB 54.2 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.1%2Bcu118-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "     ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 4.0/4.0 MB 47.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torchvision) (2.0.0)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.5.1%2Bcu118-cp312-cp312-win_amd64.whl (2700.1 MB)\n",
      "     ---------------------------------------- 0.0/2.7 GB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.7 GB 59.4 MB/s eta 0:00:46\n",
      "     ---------------------------------------- 0.0/2.7 GB 58.4 MB/s eta 0:00:46\n",
      "      --------------------------------------- 0.0/2.7 GB 58.6 MB/s eta 0:00:46\n",
      "      --------------------------------------- 0.1/2.7 GB 58.3 MB/s eta 0:00:46\n",
      "      --------------------------------------- 0.1/2.7 GB 59.0 MB/s eta 0:00:45\n",
      "     - -------------------------------------- 0.1/2.7 GB 58.7 MB/s eta 0:00:45\n",
      "     - -------------------------------------- 0.1/2.7 GB 58.6 MB/s eta 0:00:45\n",
      "     - -------------------------------------- 0.1/2.7 GB 59.0 MB/s eta 0:00:45\n",
      "     - -------------------------------------- 0.1/2.7 GB 58.8 MB/s eta 0:00:45\n",
      "     - -------------------------------------- 0.1/2.7 GB 58.7 MB/s eta 0:00:44\n",
      "     -- ------------------------------------- 0.1/2.7 GB 58.7 MB/s eta 0:00:44\n",
      "     -- ------------------------------------- 0.2/2.7 GB 58.9 MB/s eta 0:00:44\n",
      "     -- ------------------------------------- 0.2/2.7 GB 58.8 MB/s eta 0:00:44\n",
      "     -- ------------------------------------- 0.2/2.7 GB 58.7 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 58.7 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 0.2/2.7 GB 58.9 MB/s eta 0:00:43\n",
      "     --- ------------------------------------ 0.2/2.7 GB 58.9 MB/s eta 0:00:43\n",
      "     --- ------------------------------------ 0.2/2.7 GB 58.8 MB/s eta 0:00:43\n",
      "     --- ------------------------------------ 0.2/2.7 GB 58.7 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.3/2.7 GB 58.8 MB/s eta 0:00:42\n",
      "     --- ------------------------------------ 0.3/2.7 GB 59.0 MB/s eta 0:00:42\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 58.8 MB/s eta 0:00:42\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 58.8 MB/s eta 0:00:42\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 58.6 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 58.8 MB/s eta 0:00:41\n",
      "     ---- ----------------------------------- 0.3/2.7 GB 58.8 MB/s eta 0:00:41\n",
      "     ----- ---------------------------------- 0.3/2.7 GB 58.8 MB/s eta 0:00:41\n",
      "     ----- ---------------------------------- 0.3/2.7 GB 58.8 MB/s eta 0:00:40\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 58.8 MB/s eta 0:00:40\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 58.8 MB/s eta 0:00:40\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 58.6 MB/s eta 0:00:40\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 57.4 MB/s eta 0:00:41\n",
      "     ----- ---------------------------------- 0.4/2.7 GB 56.6 MB/s eta 0:00:41\n",
      "     ------ --------------------------------- 0.4/2.7 GB 55.3 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.4/2.7 GB 54.9 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.4/2.7 GB 54.9 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.4/2.7 GB 54.9 MB/s eta 0:00:42\n",
      "     ------ --------------------------------- 0.5/2.7 GB 55.0 MB/s eta 0:00:41\n",
      "     ------ --------------------------------- 0.5/2.7 GB 54.9 MB/s eta 0:00:41\n",
      "     ------- -------------------------------- 0.5/2.7 GB 55.0 MB/s eta 0:00:41\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.9 MB/s eta 0:00:41\n",
      "     ------- -------------------------------- 0.5/2.7 GB 54.9 MB/s eta 0:00:40\n",
      "     ------- -------------------------------- 0.5/2.7 GB 55.1 MB/s eta 0:00:40\n",
      "     ------- -------------------------------- 0.5/2.7 GB 55.7 MB/s eta 0:00:39\n",
      "     -------- ------------------------------- 0.5/2.7 GB 55.0 MB/s eta 0:00:40\n",
      "     -------- ------------------------------- 0.6/2.7 GB 55.1 MB/s eta 0:00:39\n",
      "     -------- ------------------------------- 0.6/2.7 GB 55.0 MB/s eta 0:00:39\n",
      "     -------- ------------------------------- 0.6/2.7 GB 54.9 MB/s eta 0:00:39\n",
      "     -------- ------------------------------- 0.6/2.7 GB 54.9 MB/s eta 0:00:39\n",
      "     --------- ------------------------------ 0.6/2.7 GB 55.1 MB/s eta 0:00:38\n",
      "     --------- ------------------------------ 0.6/2.7 GB 54.9 MB/s eta 0:00:38\n",
      "     --------- ------------------------------ 0.6/2.7 GB 55.0 MB/s eta 0:00:38\n",
      "     --------- ------------------------------ 0.6/2.7 GB 55.1 MB/s eta 0:00:38\n",
      "     --------- ------------------------------ 0.7/2.7 GB 56.8 MB/s eta 0:00:36\n",
      "     --------- ------------------------------ 0.7/2.7 GB 58.0 MB/s eta 0:00:36\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 58.4 MB/s eta 0:00:35\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 58.4 MB/s eta 0:00:35\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 58.6 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 58.4 MB/s eta 0:00:34\n",
      "     ---------- ----------------------------- 0.7/2.7 GB 58.4 MB/s eta 0:00:34\n",
      "     ----------- ---------------------------- 0.7/2.7 GB 58.4 MB/s eta 0:00:34\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 58.4 MB/s eta 0:00:34\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 58.4 MB/s eta 0:00:34\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 58.2 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 58.2 MB/s eta 0:00:33\n",
      "     ----------- ---------------------------- 0.8/2.7 GB 58.4 MB/s eta 0:00:33\n",
      "     ------------ --------------------------- 0.8/2.7 GB 58.4 MB/s eta 0:00:33\n",
      "     ------------ --------------------------- 0.8/2.7 GB 58.2 MB/s eta 0:00:33\n",
      "     ------------ --------------------------- 0.8/2.7 GB 58.2 MB/s eta 0:00:32\n",
      "     ------------ --------------------------- 0.9/2.7 GB 58.4 MB/s eta 0:00:32\n",
      "     ------------ --------------------------- 0.9/2.7 GB 58.4 MB/s eta 0:00:32\n",
      "     ------------- -------------------------- 0.9/2.7 GB 58.4 MB/s eta 0:00:32\n",
      "     ------------- -------------------------- 0.9/2.7 GB 58.4 MB/s eta 0:00:31\n",
      "     ------------- -------------------------- 0.9/2.7 GB 58.4 MB/s eta 0:00:31\n",
      "     ------------- -------------------------- 0.9/2.7 GB 58.2 MB/s eta 0:00:31\n",
      "     ------------- -------------------------- 0.9/2.7 GB 58.6 MB/s eta 0:00:31\n",
      "     -------------- ------------------------- 0.9/2.7 GB 58.8 MB/s eta 0:00:30\n",
      "     -------------- ------------------------- 1.0/2.7 GB 58.6 MB/s eta 0:00:30\n",
      "     -------------- ------------------------- 1.0/2.7 GB 58.6 MB/s eta 0:00:30\n",
      "     -------------- ------------------------- 1.0/2.7 GB 58.8 MB/s eta 0:00:30\n",
      "     -------------- ------------------------- 1.0/2.7 GB 58.8 MB/s eta 0:00:29\n",
      "     -------------- ------------------------- 1.0/2.7 GB 58.6 MB/s eta 0:00:30\n",
      "     -------------- ------------------------- 1.0/2.7 GB 56.1 MB/s eta 0:00:31\n",
      "     --------------- ------------------------ 1.0/2.7 GB 56.1 MB/s eta 0:00:30\n",
      "     --------------- ------------------------ 1.0/2.7 GB 56.1 MB/s eta 0:00:30\n",
      "     --------------- ------------------------ 1.0/2.7 GB 55.5 MB/s eta 0:00:30\n",
      "     --------------- ------------------------ 1.1/2.7 GB 55.5 MB/s eta 0:00:30\n",
      "     --------------- ------------------------ 1.1/2.7 GB 55.7 MB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 55.5 MB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 55.5 MB/s eta 0:00:29\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 55.5 MB/s eta 0:00:29\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 55.7 MB/s eta 0:00:29\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 55.7 MB/s eta 0:00:29\n",
      "     ---------------- ----------------------- 1.1/2.7 GB 55.7 MB/s eta 0:00:28\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 55.5 MB/s eta 0:00:28\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 55.5 MB/s eta 0:00:28\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 55.5 MB/s eta 0:00:28\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 55.5 MB/s eta 0:00:28\n",
      "     ----------------- ---------------------- 1.2/2.7 GB 55.5 MB/s eta 0:00:27\n",
      "     ------------------ --------------------- 1.2/2.7 GB 55.5 MB/s eta 0:00:27\n",
      "     ------------------ --------------------- 1.2/2.7 GB 55.5 MB/s eta 0:00:27\n",
      "     ------------------ --------------------- 1.2/2.7 GB 55.5 MB/s eta 0:00:27\n",
      "     ------------------ --------------------- 1.3/2.7 GB 55.5 MB/s eta 0:00:26\n",
      "     ------------------ --------------------- 1.3/2.7 GB 58.0 MB/s eta 0:00:25\n",
      "     ------------------- -------------------- 1.3/2.7 GB 58.2 MB/s eta 0:00:25\n",
      "     ------------------- -------------------- 1.3/2.7 GB 58.6 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 58.6 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 59.0 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 58.8 MB/s eta 0:00:24\n",
      "     ------------------- -------------------- 1.3/2.7 GB 58.6 MB/s eta 0:00:24\n",
      "     -------------------- ------------------- 1.4/2.7 GB 58.8 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.4/2.7 GB 58.8 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.4/2.7 GB 58.8 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.4/2.7 GB 58.6 MB/s eta 0:00:23\n",
      "     -------------------- ------------------- 1.4/2.7 GB 58.8 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.4/2.7 GB 58.8 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.4/2.7 GB 58.8 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.4/2.7 GB 58.6 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.5/2.7 GB 58.8 MB/s eta 0:00:22\n",
      "     --------------------- ------------------ 1.5/2.7 GB 58.6 MB/s eta 0:00:21\n",
      "     --------------------- ------------------ 1.5/2.7 GB 58.8 MB/s eta 0:00:21\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 59.0 MB/s eta 0:00:21\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 58.8 MB/s eta 0:00:21\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 58.6 MB/s eta 0:00:21\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 58.6 MB/s eta 0:00:20\n",
      "     ---------------------- ----------------- 1.5/2.7 GB 58.8 MB/s eta 0:00:20\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 58.8 MB/s eta 0:00:20\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 58.8 MB/s eta 0:00:20\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 58.6 MB/s eta 0:00:20\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 58.6 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 58.8 MB/s eta 0:00:19\n",
      "     ----------------------- ---------------- 1.6/2.7 GB 58.8 MB/s eta 0:00:19\n",
      "     ------------------------ --------------- 1.6/2.7 GB 58.6 MB/s eta 0:00:19\n",
      "     ------------------------ --------------- 1.6/2.7 GB 59.0 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 58.8 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 58.8 MB/s eta 0:00:18\n",
      "     ------------------------ --------------- 1.7/2.7 GB 58.6 MB/s eta 0:00:18\n",
      "     ------------------------- -------------- 1.7/2.7 GB 58.8 MB/s eta 0:00:18\n",
      "     ------------------------- -------------- 1.7/2.7 GB 58.8 MB/s eta 0:00:17\n",
      "     ------------------------- -------------- 1.7/2.7 GB 58.8 MB/s eta 0:00:17\n",
      "     ------------------------- -------------- 1.7/2.7 GB 58.8 MB/s eta 0:00:17\n",
      "     ------------------------- -------------- 1.7/2.7 GB 58.6 MB/s eta 0:00:17\n",
      "     -------------------------- ------------- 1.8/2.7 GB 58.8 MB/s eta 0:00:17\n",
      "     -------------------------- ------------- 1.8/2.7 GB 58.6 MB/s eta 0:00:16\n",
      "     -------------------------- ------------- 1.8/2.7 GB 58.8 MB/s eta 0:00:16\n",
      "     -------------------------- ------------- 1.8/2.7 GB 58.8 MB/s eta 0:00:16\n",
      "     -------------------------- ------------- 1.8/2.7 GB 58.8 MB/s eta 0:00:16\n",
      "     -------------------------- ------------- 1.8/2.7 GB 58.8 MB/s eta 0:00:15\n",
      "     --------------------------- ------------ 1.8/2.7 GB 58.8 MB/s eta 0:00:15\n",
      "     --------------------------- ------------ 1.8/2.7 GB 58.8 MB/s eta 0:00:15\n",
      "     --------------------------- ------------ 1.9/2.7 GB 58.8 MB/s eta 0:00:15\n",
      "     --------------------------- ------------ 1.9/2.7 GB 58.8 MB/s eta 0:00:15\n",
      "     --------------------------- ------------ 1.9/2.7 GB 58.8 MB/s eta 0:00:14\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 58.8 MB/s eta 0:00:14\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 58.8 MB/s eta 0:00:14\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 58.8 MB/s eta 0:00:14\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 58.8 MB/s eta 0:00:14\n",
      "     ---------------------------- ----------- 1.9/2.7 GB 59.0 MB/s eta 0:00:13\n",
      "     ---------------------------- ----------- 2.0/2.7 GB 59.0 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 58.8 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 59.0 MB/s eta 0:00:13\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 58.8 MB/s eta 0:00:12\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 59.0 MB/s eta 0:00:12\n",
      "     ----------------------------- ---------- 2.0/2.7 GB 58.8 MB/s eta 0:00:12\n",
      "     ------------------------------ --------- 2.0/2.7 GB 59.0 MB/s eta 0:00:12\n",
      "     ------------------------------ --------- 2.0/2.7 GB 58.8 MB/s eta 0:00:12\n",
      "     ------------------------------ --------- 2.1/2.7 GB 58.8 MB/s eta 0:00:11\n",
      "     ------------------------------ --------- 2.1/2.7 GB 58.8 MB/s eta 0:00:11\n",
      "     ------------------------------ --------- 2.1/2.7 GB 58.8 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 59.0 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 58.8 MB/s eta 0:00:11\n",
      "     ------------------------------- -------- 2.1/2.7 GB 58.8 MB/s eta 0:00:10\n",
      "     ------------------------------- -------- 2.1/2.7 GB 58.8 MB/s eta 0:00:10\n",
      "     ------------------------------- -------- 2.1/2.7 GB 59.0 MB/s eta 0:00:10\n",
      "     ------------------------------- -------- 2.2/2.7 GB 59.0 MB/s eta 0:00:10\n",
      "     -------------------------------- ------- 2.2/2.7 GB 58.8 MB/s eta 0:00:10\n",
      "     -------------------------------- ------- 2.2/2.7 GB 58.6 MB/s eta 0:00:09\n",
      "     -------------------------------- ------- 2.2/2.7 GB 59.0 MB/s eta 0:00:09\n",
      "     -------------------------------- ------- 2.2/2.7 GB 58.8 MB/s eta 0:00:09\n",
      "     -------------------------------- ------- 2.2/2.7 GB 58.6 MB/s eta 0:00:09\n",
      "     --------------------------------- ------ 2.2/2.7 GB 58.6 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.2/2.7 GB 58.6 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.3/2.7 GB 58.6 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.3/2.7 GB 58.6 MB/s eta 0:00:08\n",
      "     --------------------------------- ------ 2.3/2.7 GB 58.6 MB/s eta 0:00:08\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 58.6 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 58.6 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 58.4 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 58.4 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.3/2.7 GB 58.2 MB/s eta 0:00:07\n",
      "     ---------------------------------- ----- 2.4/2.7 GB 58.4 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 58.4 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 58.4 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 58.2 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 58.2 MB/s eta 0:00:06\n",
      "     ----------------------------------- ---- 2.4/2.7 GB 58.4 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.4/2.7 GB 58.4 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.4/2.7 GB 58.4 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.5/2.7 GB 58.4 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.5/2.7 GB 57.8 MB/s eta 0:00:05\n",
      "     ------------------------------------ --- 2.5/2.7 GB 57.2 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.5/2.7 GB 56.6 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 56.4 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 56.4 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 56.4 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.5/2.7 GB 56.4 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.5/2.7 GB 56.6 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.6/2.7 GB 56.6 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 56.8 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 56.8 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.6/2.7 GB 56.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 56.2 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 55.9 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.6/2.7 GB 56.1 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.6/2.7 GB 56.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 56.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 GB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.7/2.7 GB 12.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "Successfully installed torch-2.5.1+cu118 torchaudio-2.5.1+cu118 torchvision-0.20.1+cu118\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# Hugging Face 토큰 가져오기\n",
    "hf_token = os.getenv(\"HF_ACCESS_TOKEN\")\n",
    "\n",
    "# Hugging Face Access Token 입력\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5738a0610a48c8a34503c20ac2ecca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/40.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dm705\\.cache\\huggingface\\hub\\models--unsloth--gemma-2b-it-bnb-4bit. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab736b81f3644e0391766935ed4b8353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86483938c2d547b08846ea3d2c1e045e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8af1e750c544d390aa310970d9c0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4af3aec7fdd4003908c679cfa125274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "ename": "PackageNotFoundError",
     "evalue": "No package metadata was found for bitsandbytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\metadata\\__init__.py:397\u001b[0m, in \u001b[0;36mDistribution.from_name\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscover\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[0;32m      8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsloth/gemma-2b-it-bnb-4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munsloth/gemma-2b-it-bnb-4bit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 테스트 입력\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# test_input = \"Explain quantum mechanics in simple terms.\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(transcription, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\transformers\\modeling_utils.py:3659\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_quantized \u001b[38;5;129;01mor\u001b[39;00m quantization_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pre_quantized:\n\u001b[1;32m-> 3659\u001b[0m         config\u001b[38;5;241m.\u001b[39mquantization_config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoHfQuantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_quantization_configs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3660\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\n\u001b[0;32m   3661\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3662\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3663\u001b[0m         config\u001b[38;5;241m.\u001b[39mquantization_config \u001b[38;5;241m=\u001b[39m quantization_config\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\transformers\\quantizers\\auto.py:173\u001b[0m, in \u001b[0;36mAutoHfQuantizer.merge_quantization_configs\u001b[1;34m(cls, quantization_config, quantization_config_from_args)\u001b[0m\n\u001b[0;32m    170\u001b[0m     warning_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(quantization_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 173\u001b[0m     quantization_config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoQuantizationConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(quantization_config, (GPTQConfig, AwqConfig, FbgemmFp8Config))\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m quantization_config_from_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    178\u001b[0m ):\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# special case for GPTQ / AWQ / FbgemmFp8 config collision\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     loading_attr_dict \u001b[38;5;241m=\u001b[39m quantization_config_from_args\u001b[38;5;241m.\u001b[39mget_loading_attributes()\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\transformers\\quantizers\\auto.py:103\u001b[0m, in \u001b[0;36mAutoQuantizationConfig.from_dict\u001b[1;34m(cls, quantization_config_dict)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown quantization type, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquant_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - supported types are:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(AUTO_QUANTIZER_MAPPING\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m     )\n\u001b[0;32m    102\u001b[0m target_cls \u001b[38;5;241m=\u001b[39m AUTO_QUANTIZATION_CONFIG_MAPPING[quant_method]\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantization_config_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\transformers\\utils\\quantization_config.py:102\u001b[0m, in \u001b[0;36mQuantizationConfigMixin.from_dict\u001b[1;34m(cls, config_dict, return_unused_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_dict\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config_dict, return_unused_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m    Instantiates a [`QuantizationConfigMixin`] from a Python dictionary of parameters.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m        [`QuantizationConfigMixin`]: The configuration object instantiated from those parameters.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     to_remove \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\transformers\\utils\\quantization_config.py:417\u001b[0m, in \u001b[0;36mBitsAndBytesConfig.__init__\u001b[1;34m(self, load_in_8bit, load_in_4bit, llm_int8_threshold, llm_int8_skip_modules, llm_int8_enable_fp32_cpu_offload, llm_int8_has_fp16_weight, bnb_4bit_compute_dtype, bnb_4bit_quant_type, bnb_4bit_use_double_quant, bnb_4bit_quant_storage, **kwargs)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    415\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnused kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. These kwargs are not used in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 417\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_영어대화-UlUCYZce-py3.12\\Lib\\site-packages\\transformers\\utils\\quantization_config.py:475\u001b[0m, in \u001b[0;36mBitsAndBytesConfig.post_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbnb_4bit_use_double_quant, \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbnb_4bit_use_double_quant must be a boolean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_in_4bit \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(\u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbitsandbytes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.39.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    477\u001b[0m ):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4 bit quantization requires bitsandbytes>=0.39.0 - please upgrade your bitsandbytes version\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    480\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\metadata\\__init__.py:889\u001b[0m, in \u001b[0;36mversion\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mversion\u001b[39m(distribution_name):\n\u001b[0;32m    883\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the version string for the named package.\u001b[39;00m\n\u001b[0;32m    884\u001b[0m \n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package to query.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m    :return: The version string for the package as defined in the package's\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m        \"Version\" metadata key.\u001b[39;00m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mversion\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\metadata\\__init__.py:862\u001b[0m, in \u001b[0;36mdistribution\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistribution\u001b[39m(distribution_name):\n\u001b[0;32m    857\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the ``Distribution`` instance for the named package.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \n\u001b[0;32m    859\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package as a string.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;124;03m    :return: A ``Distribution`` instance (or subclass thereof).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\metadata\\__init__.py:399\u001b[0m, in \u001b[0;36mDistribution.from_name\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdiscover(name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(name)\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m: No package metadata was found for bitsandbytes"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# 4-bit 양자화된 모델 로드\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/gemma-2b-it-bnb-4bit\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"unsloth/gemma-2b-it-bnb-4bit\")\n",
    "\n",
    "# 테스트 입력\n",
    "# test_input = \"Explain quantum mechanics in simple terms.\"\n",
    "inputs = tokenizer(transcription, return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs[\"input_ids\"], max_length=100, num_return_sequences=1)\n",
    "\n",
    "# 결과 확인\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 라이브러리 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 설명\n",
    "\n",
    "- 1. 오디오 처리\n",
    "  - numpy, librosa, soundfile, pydub\n",
    "  - numpy 명시한 버전 외에 2.0버전도 사용 가능 \n",
    "\n",
    "- 2. 모델 실행\n",
    "  - librosa soundfile pydub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (4.47.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (1.2.1)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from accelerate) (6.1.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from langchain) (3.11.11)\n",
      "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain)\n",
      "  Using cached langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.2.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.6.0-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.15.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.29->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.13-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
      "Using cached langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
      "Using cached sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Using cached langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
      "Using cached langchain_text_splitters-0.3.4-py3-none-any.whl (27 kB)\n",
      "Using cached langsmith-0.2.10-py3-none-any.whl (326 kB)\n",
      "Using cached pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached scikit_learn-1.6.0-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Using cached scipy-1.15.0-cp312-cp312-win_amd64.whl (43.6 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached orjson-3.10.13-cp312-cp312-win_amd64.whl (135 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, tenacity, scipy, pydantic-core, Pillow, orjson, jsonpatch, joblib, greenlet, annotated-types, SQLAlchemy, scikit-learn, requests-toolbelt, pydantic, langsmith, langchain-core, sentence-transformers, langchain-text-splitters, langchain\n",
      "Successfully installed Pillow-11.1.0 SQLAlchemy-2.0.36 annotated-types-0.7.0 greenlet-3.1.1 joblib-1.4.2 jsonpatch-1.33 langchain-0.3.14 langchain-core-0.3.29 langchain-text-splitters-0.3.4 langsmith-0.2.10 orjson-3.10.13 pydantic-2.10.4 pydantic-core-2.27.2 requests-toolbelt-1.0.0 scikit-learn-1.6.0 scipy-1.15.0 sentence-transformers-3.3.1 tenacity-9.0.0 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers accelerate langchain sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.23.4\n",
      "  Using cached numpy-1.23.4.tar.gz (10.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [33 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_\\xec쁺\\xec뼱\\xeb\\x8c\\x80\\xed솕-UlUCYZce-py3.12\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_\\xec쁺\\xec뼱\\xeb\\x8c\\x80\\xed솕-UlUCYZce-py3.12\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_\\xec쁺\\xec뼱\\xeb\\x8c\\x80\\xed솕-UlUCYZce-py3.12\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 112, in get_requires_for_build_wheel\n",
      "          backend = _build_backend()\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai_\\xec쁺\\xec뼱\\xeb\\x8c\\x80\\xed솕-UlUCYZce-py3.12\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\n",
      "          obj = import_module(mod_path)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "          return _bootstrap._gcd_import(name[level:], package, level)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "        File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
      "        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "        File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "        File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "        File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Temp\\pip-build-env-4nq6pjul\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 16, in <module>\n",
      "          import setuptools.version\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Temp\\pip-build-env-4nq6pjul\\overlay\\Lib\\site-packages\\setuptools\\version.py\", line 1, in <module>\n",
      "          import pkg_resources\n",
      "        File \"C:\\Users\\dm705\\AppData\\Local\\Temp\\pip-build-env-4nq6pjul\\overlay\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 2172, in <module>\n",
      "          register_finder(pkgutil.ImpImporter, find_on_path)\n",
      "                          ^^^^^^^^^^^^^^^^^^^\n",
      "      AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.23.4 librosa soundfile pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Using cached librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from librosa) (2.0.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from librosa) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Using cached numba-0.60.0-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Using cached soundfile-0.13.0-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Using cached soxr-0.5.0.post1-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Collecting lazy-loader>=0.1 (from librosa)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Using cached msgpack-1.1.0-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Using cached llvmlite-0.43.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dm705\\appdata\\local\\pypoetry\\cache\\virtualenvs\\ai_영어대화-ulucyzce-py3.12\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.12.14)\n",
      "Using cached librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached msgpack-1.1.0-cp312-cp312-win_amd64.whl (75 kB)\n",
      "Using cached numba-0.60.0-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached soundfile-0.13.0-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Using cached soxr-0.5.0.post1-cp312-abi3-win_amd64.whl (164 kB)\n",
      "Using cached llvmlite-0.43.0-cp312-cp312-win_amd64.whl (28.1 MB)\n",
      "Installing collected packages: soxr, msgpack, llvmlite, lazy-loader, audioread, soundfile, pooch, numba, librosa\n",
      "Successfully installed audioread-3.0.1 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.43.0 msgpack-1.1.0 numba-0.60.0 pooch-1.8.2 soundfile-0.13.0 soxr-0.5.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. 모델 불러오기 및 파이프라인 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype,\n",
    "    # low_cpu_mem_usage=True, \n",
    "    use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': '0d38672e0bbdbdc460af55b8bb84a15b2730db2819f2af64f9c777d4d586f2de',\n",
       "  'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00024414, 0.00048828,\n",
       "         0.0005188 ]),\n",
       "  'sampling_rate': 16000}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[0]['audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '0d38672e0bbdbdc460af55b8bb84a15b2730db2819f2af64f9c777d4d586f2de',\n",
       " 'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00024414, 0.00048828,\n",
       "        0.0005188 ]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "slice(0, 30000, None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 30초 단위로 분할\u001b[39;00m\n\u001b[0;32m      8\u001b[0m chunk_length_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# 30초\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m chunks \u001b[38;5;241m=\u001b[39m [\u001b[43maudio\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk_length_ms\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(audio), chunk_length_ms)]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 각 분할 저장\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunks):\n",
      "\u001b[1;31mKeyError\u001b[0m: slice(0, 30000, None)"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# 오디오 파일 로드\n",
    "# audio = AudioSegment.from_file(\"path_to_audio_file.wav\")\n",
    "audio = sample\n",
    "\n",
    "# 30초 단위로 분할\n",
    "chunk_length_ms = 30 * 1000  # 30초\n",
    "chunks = [audio[i:i + chunk_length_ms] for i in range(0, len(audio), chunk_length_ms)]\n",
    "\n",
    "# 각 분할 저장\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.export(f\"chunk_{i}.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(len(chunks)):\n",
    "    result = model(f\"chunk_{i}.wav\")\n",
    "    results.append(result[\"text\"])\n",
    "\n",
    "# 결과 합치기\n",
    "final_transcription = \" \".join(results)\n",
    "print(final_transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

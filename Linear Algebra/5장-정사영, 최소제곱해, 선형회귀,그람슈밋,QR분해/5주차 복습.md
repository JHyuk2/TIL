# 4.3) 정사영과 최소제곱해, QR분해

### a) 정사영 (projection)

1) 정사영 - W에 직교(orthogonal)인 벡터들의 집합

2) W를 부분공간이라 하고, M의 열벡터들이 W의 기저를 이룰 때

```python
# proj_wX = M (M.transpose() * M).inverse() * M.transpose * X
proj_aX = ta = (a.transpose() * X / a.transpose() * a) * a
```



### b) 최소제곱해 (least square solution),선형회귀 (Linear Regression)

> x, y에 대한 2차원 데이터가 주어져 있다고 하면 (x1, y1) ... (xn, yn)
>
> 이제 이 데이터로부터 x, y의 관계를 가장 잘 나타내는 선형모델(방정식) y= a + bx를 찾아보자.
>
> 이상적인 상황은 모든 데이터 (xi, yi) 에 대해 yi = a + bxi를 만족하는 것.

하지만 측정에서 생기는 오차의 영역이 생기는데, 이 때 미지수의 개수보다 방정식의 개수가 많은 over-determined 선형연립장정식이 생기는데, 이때 ax~~ b 를 만족하는 근사해 **(오차가 최소가 되는 근사해)**를 찾는 문제를 `최소제곱문제` 라고 한다.

 ![최소제곱](C:\Users\win\Hyuk2Coding\TIL\my_DS\선형대수응용\5주차_정사영, 최소제곱해, 선형회귀, 그람슈밋, QR분해\최소제곱.jpg)

> 즉 선을 하나 그었을 때, 각각의 점으로부터 직선까지의 거리가 최소가 되는 선을 구하는 것.

```python
# example - 최소제곱라인 구하기
A = matrix([[1, 0],
            [1, 1],
            [1, 2],
            [1, 3]]
)
b = vector([1, 3, 4, 4])
print((A.transpose() * A).inverse() * A.transpose()*b)
```

즉, y = c + dx꼴로 나타낼 수 있도록 값을 찾는 것이 선형회귀라고 볼 수 있고, 그것을 통해 오차값을 최소로 줄이는 과정을 최소제곱해를 구하는 과정이라고 생각하면 될 것 같다.



### c) 직교행렬(real orthogonal matrix)

정사각행렬 A에 대하여 A.inverse() = A.transpose() 인 경우, 직교행렬이라 한다.

A가 직교행렬이면 다음을 만족한다.

1) A의 행벡터들은 서로 직교이며, 정규벡터이다.

2) A의 열벡터들은 서로 직교이며, 정규벡터이다.

3) A는 가역행렬이다.

**4) ||Ax|| = ||x|| 를 만족한다. (즉, 길이를 보존한다.)** -- 가장 중요!!!



### d) QR분해 (QR decomposition)

> 실수행렬을 직교행렬과 상삼각행렬의 곱으로 나타내는 행렬 분해이다.

행렬  A(m by n행렬)에 대하여, **A = Q[R, 0]** 으로 분해될 수 있다.

- Q: 직교행렬
- R: 상삼각행렬
- m == n일 때, A가 가역이면, QR 분해는 유일해를 갖는다.

### e) 그람-슈미트 직교화(Gram-Schmidt)

정규직교기저(orthonormal basis) => Rn의 기저 S가 직교집합이면 직교기저, 정규직교집합이면 정규직교기저 라고 한다.

**그람 슈미트 직교화**

> 주어진 벡터들에 대한 직교기저(orthogonal basis) 또는 정규직교기저(orthonormal basis)를 구하는 과정이다.

```python
# sage example
X1 = vector([1, 1, 0])
X2 = vector([0, 1, 2])
X3 = vector([1, 2, 1])
A = matrix([x1, x2, x3])

#직교화 과정
[G, mu] = A.gram_schmidt() # 행에 대하여 직교기저를 찾는다. A == mu*G

# 정규화 과정
N = matrix([G.row(i) / G.row(i).norm() for i in range(0, 3)])
```




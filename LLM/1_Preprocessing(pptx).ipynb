{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cmd로 gguf파일 다운로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "huggingface-cli download \\\n",
    "  heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF \\\n",
    "  ggml-model-Q5_K_M.gguf \\\n",
    "  --local-dir C:/Users/dm705/Study \\\n",
    "  --local-dir-use-symlinks False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이래도 api 뜨나..?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `*.pptx` file에서 텍스트 추출하기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모델 불러오기(EEVE-Korean-10.8B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "requirements: pip install langchain\n",
    "\"\"\"\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama   \n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.callbacks.manager import CallbackManager\n",
    "from langchain import LLMChain\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"EEVE-Korean-10.8B:latest\",\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 프롬프트 템플릿 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(torch.device(\"cuda:0\"))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "# 2. 프롬프트 템플릿 만들기\n",
    "template = \"\"\"\n",
    "입력된 텍스트를 문장 단위로 나누어 주세요:\n",
    "{text}\n",
    "\n",
    "나뉘어진 문장별로 번호를 매겨 나누어 정리해 주십시오.\n",
    "결과물 출력 외에 질문이나 답변은 하지 마십시오.\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 3. 출력 파서 설정하기\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 4. LLMChain 만들기\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt, output_parser=output_parser)\n",
    "# chain = llm | prompt | output_parser\n",
    "\n",
    "# 5. 텍스트 입력하고 실행하기\n",
    "input_text = \"\"\"\n",
    "장애인 업무의 한계를 없애다 상시 근로자 100,016 명 / 장애인 근로자 1,386 명 (1.54%) * 2018.12 월 기준 장애물 없는 생활환경 (Barrier Free) 자체 인증 제도를 각 사업장에 도입 상담심리사를 상주시켜 직무갈등 , 대인관계 등 고충을 해결 업무에 집중할 환경을 마련 장애인 고객의 입장에서 바라본 기술개발에도 적극 참여 장애인은 단순 업무만 해야 하나 ? ‘ 삼성전자 맞춤형 인재 ’ 로 성장하는데 있어서 비장애인과 장애인의 구분은 의미가 없다고 판단 , 직무교육을 거쳐 고용된 장애인은 각 사업장에서 전기 · 전자 , 정보기술 , 기계디자인 분야에서 근무 중 장애인고용 기업 사례 장애인 고용 전문가와 함께 다양한 장애인 고용 대책 마련\n",
    "\"\"\"\n",
    "\n",
    "# LLMChain 실행하기\n",
    "result = llm_chain.invoke({\"text\": input_text})\n",
    "# result = chain.invoke({\"text\": input_text})\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 전처리 - 문장 구분하기 (using Ollama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 5. CSV 파일 읽고 처리하기\n",
    "input_csv_path = \"extract_text_[PPT] 직장 내 장애인 인식개선 교육 표준교안 PPT(국문)_수정.csv\"\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# 텍스트 컬럼 이름 지정\n",
    "text_column = \"Text\"\n",
    "\n",
    "# 결과 저장할 리스트\n",
    "results = []\n",
    "\n",
    "# 각 텍스트에 대해 처리\n",
    "for text in df[text_column]:\n",
    "    result = llm_chain.run({\"text\": text})\n",
    "    results.append(result)\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "df[\"processed_text\"] = results\n",
    "\n",
    "# 결과를 새로운 CSV 파일로 저장\n",
    "output_csv_path = \"output.csv\"\n",
    "df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[4]['processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

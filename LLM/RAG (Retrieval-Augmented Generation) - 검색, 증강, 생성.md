## RAG (Retrieval-Augmented Generation) - 검색, 증강, 생성

### 1. RAG란?

간단히 말하면 GPT에 정보검색 기능을 추가하는 것.

> 여기서 정보검색 내부 문서가 될 수도 있고, 인터넷 검색이 될 수도 있음.



### RAG 기술이 주목받고 있는 이유

#### ChatGPT가 가질 수 있는 문제점을 해결 할 수 있기 때문.

1. **최신 정보**에 대하여 학습되어 있지 않다.
2. **내부데이터**에 대한 학습이 되어 있지 않다.
3. 특정 도메인(개인정보 혹은 재부 정보)에 대한 기대하는 답변을 얻을 수 없다.
4. 문서의 양이 많아질 수록 **할루시네이션(환각) 현상**이 심해진다.



적합한 RAG를 적용하게 되면?

1. **최신 정보**를 기반으로 답변할 수 있으며, 정보를 찾을 수 없는 경우 "검색" 기능을 활용할 수 있다.
2. 내부데이터를 참고하여 답변할 수 있다.
3. 내부 DB에 저장할 수 있고, DB에 내용을 축적해 나갈 수 있으며, 저장된 DB에서 원하는 정보를 검색하여 검색된 정보를 바탕으로 답변받을 수 있다.
4. 할루시네이션 현상을 줄일 수 있다.

> 궁극적으로 더 나은 답변 품질을 기대할 수 있으며, 방대한 지식 기반으로 답변하는 도메인 특화 챗봇을 생성 할 수 있다. (우리가 축적해 나가는 DB 기준으로 특화된 챗봇을 만들 수 있게 된다.)



### ChatGPT 안에 내장된 RAG?

GPT에 문서를 업로드 한 후 질문을 하게 되면, 문서를 기반으로 답변을 하게 됨.

OpenAI는 RAG의 전반적인 과정(내부 내용)은 블랙박스로 되어있기 때문에 우리가 자세히 알 수 없음.

하지만, 문서 내부 구체적인 질문에는 제대로된 답변을 하지 못하거나, 관련 정보를 찾지 못하기도 함.

> 할루시네이션은 덤 ^^7



ChatGPT의 **RAG는 우리가 컨트롤할 수 없는 영역**이기 때문에, 

**유일한 최선은 "문서"를 GPT가 가장 잘 검색할 수 있는 형태로 변경하는 것.**

하지만, 모든 문서의 형태를 모두 변경하는 것은 사실상 어려운 일이다.



### 2. RAG 프로세스의 이해

![RAG Process](..\assets\RAG process.png)

RAG가 차지하는 부분이 생각보다 크고, 이 부분을 한땀한땀 컨트롤한다면 더 좋은 결과가 나올 수 있다.



### 3. 좋은 답변을 얻기 위해선?

1. RAG (Context optimization - What the model need to know)
2. Prompt engineering
3. Fine-tuning (LLM optimization - the domain model specialize)
   - Full Fine-tuning이란 것도 있지만, 개인이 하는 단계에서는 사실상 불가능하다.



> 구현 난이도 :  prompt engineering <  RAG < Fine-tuning (가장 어려움)
>
> 최신 정보 반영: Fine-tuning < prompt engineering < RAG
>
> 유도과정 해석 : Fine-tuning & prompt engineering < RAG (Response Tracing이 가능하다.)




{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새싹 해커톤\n",
    "## 나란히 - 장애인 인식 개선을 위한 생성형AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PDF를 읽어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1) PyPDF2, PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고용장려금\n",
      "경증남성\n",
      "경증여성\n",
      "중증남성\n",
      "중증여성\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page in range(len(reader.pages)):\n",
    "            text += reader.pages[page].extract_text()\n",
    "    return text\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "\n",
    "def read_pdf_with_pymupdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    text = ''\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)  # 페이지 불러오기\n",
    "        text += page.get_text()  # 페이지에서 텍스트 추출\n",
    "    return text\n",
    "\n",
    "\n",
    "pdf_text = read_pdf_with_pymupdf('./dataset/[PPT] 직장 내 장애인 인식개선 교육 표준교안 PPT(국문)_수정.pdf')\n",
    "print(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고용장려금경증남성 경증여성\n",
      "중증남성 중증여성\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_path = './dataset/[PPT] 직장 내 장애인 인식개선 교육 표준교안 PPT(국문)_수정.pdf'\n",
    "\n",
    "    pdf_text = read_pdf(file_path)\n",
    "    print(pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OCR인식 없이는 잘 읽히지 않는 것 같다.\n",
    "\n",
    "python에서 지원하는 PDF reader를 사용해보았지만...  \n",
    "드래그로 긁을 수 있는 형식이 아니라 그런지 잘 읽히진 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2) OCR reader (pytesseract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Requirements: `pip install pytesseract pdf2image pillow`\n",
    "\"\"\"\n",
    "\n",
    "# OCR을 사용\n",
    "\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Tesseract 경로 설정 (윈도우의 경우)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# PDF 파일 경로 설정\n",
    "pdf_path = './dataset/[PPT] 직장 내 장애인 인식개선 교육 표준교안 PPT(국문)_수정.pdf'\n",
    "\n",
    "# PDF를 이미지로 변환, 해상도 300dpi(고화질)로 조정\n",
    "pages = convert_from_path(pdf_path, 300) \n",
    "\n",
    "# 각 페이지에서 텍스트 추출\n",
    "def ocr_from_pdf(pages):\n",
    "    text = ''\n",
    "    for num, page in enumerate(pages):\n",
    "        # 이미지를 일시적으로 저장\n",
    "        temp_image_path = f\"temp_page_{num+1}.png\"\n",
    "        page.save(temp_image_path, 'PNG')\n",
    "        \n",
    "        # 이미지에서 텍스트 추출\n",
    "        page_text = pytesseract.image_to_string(Image.open(temp_image_path), lang='kor+eng')\n",
    "        text += page_text\n",
    "        \n",
    "        # 일시적 이미지 파일 삭제\n",
    "        os.remove(temp_image_path)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageFile.py:536\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m()\n\u001b[0;32m    537\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 텍스트 추출\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pdf_text \u001b[38;5;241m=\u001b[39m \u001b[43mocr_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(pdf_text)\n",
      "Cell \u001b[1;32mIn[30], line 27\u001b[0m, in \u001b[0;36mocr_from_pdf\u001b[1;34m(pages)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pages):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# 이미지를 일시적으로 저장\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     temp_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_page_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 27\u001b[0m     \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPNG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# 이미지에서 텍스트 추출\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     page_text \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_string(Image\u001b[38;5;241m.\u001b[39mopen(temp_image_path), lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkor+eng\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:2459\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2456\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2458\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2459\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2460\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   2461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\PngImagePlugin.py:1412\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[0;32m   1408\u001b[0m     im \u001b[38;5;241m=\u001b[39m _write_multiple_frames(\n\u001b[0;32m   1409\u001b[0m         im, fp, chunk, rawmode, default_image, append_images\n\u001b[0;32m   1410\u001b[0m     )\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im:\n\u001b[1;32m-> 1412\u001b[0m     \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageFile.py:540\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    538\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 540\u001b[0m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    542\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageFile.py:559\u001b[0m, in \u001b[0;36m_encode_tile\u001b[1;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 559\u001b[0m         errcode, data \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    560\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[0;32m    561\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 텍스트 추출\n",
    "pdf_text = ocr_from_pdf(pages)\n",
    "print(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('가 보입니다\\n'\n",
      " '\\n'\n",
      " '장애인 고용, 기업에게 어떤 의미가 있을까\\n'\n",
      " '\\n'\n",
      " '종료 이해하기\\n'\n",
      " '\\n'\n",
      " '느\\n'\n",
      " 'Lo\\n'\n",
      " '\\n'\n",
      " '16\\n'\n",
      " 'oll\\n'\n",
      " '\\n'\n",
      " '~\\n'\n",
      " '100\\n'\n",
      " '\\n'\n",
      " 'Al 일하기, 이렇게 하면 잘 할 수 있습니다\\n'\n",
      " '\\n'\n",
      " '한\\n'\n",
      " '=\\n'\n",
      " '\\n'\n",
      " '장애인 고용,\\n'\n",
      " '\\n'\n",
      " '기업에게 어떤 의미가 있을까\\n'\n",
      " '\\n'\n",
      " '0\\n'\n",
      " '\\n'\n",
      " '애인고용\\n'\n",
      " '\\n'\n",
      " 'iE\\n'\n",
      " '\\n'\n",
      " '기업 사례\\n'\n",
      " '\\n'\n",
      " '으로 담담히 No.1 게임 기업의 SHO! 되다!\\n'\n",
      " '\\n'\n",
      " '@.NEXON                                                             넥슨컴즈의 '\n",
      " '장애인\\n'\n",
      " '\\n'\n",
      " 'ASS 우대도 없었던 게임 산업\\n'\n",
      " '\\n'\n",
      " '위기 속 장애인 고응의 들파구       ~ 애에마테테\\n'\n",
      " '__                                                                  이중 중증장애인 '\n",
      " '비율 73% 09\\n'\n",
      " '\\n'\n",
      " '201년8넥슨커뮤니케이션즈(넥슨컴지를 설립하고\\n'\n",
      " '\\n'\n",
      " '넥슨의 게임 SO} 서비스지원과 고객 지원 업무를 담당함\\n'\n",
      " '\\n'\n",
      " '4개월간의 SSeS 거친 장애인 23명이\\n'\n",
      " '처음으로산업에입사하게됨\\n'\n",
      " '\\n'\n",
      " '“AS 홈페이지 관리, 게임 상담, 모니터링 등\\n'\n",
      " '\\n'\n",
      " '상시 근로자 2.691명 / 장애인\\n'\n",
      " '\\n'\n",
      " '근로자 39S (2.04%)\\n'\n",
      " '\\n'\n",
      " '“2018.12 기준\\n'\n",
      " '전문가와 함께\\n'\n",
      " '\\n'\n",
      " '고용 대책 마련\\n'\n",
      " '\\n'\n",
      " '장애물 없는 생활환경 (Barrier Free)\\n'\n",
      " '자체 인증 제도를 각 사업장에 도입\\n'\n",
      " '\\n'\n",
      " '상담심리사를 상주시켜\\n'\n",
      " '갈등, 대인관계 등 고중을 해결\\n'\n",
      " '\\n'\n",
      " '장매인 고객의 입장에서 바라본\\n'\n",
      " '기술개발에도 적극 참여\\n'\n",
      " '\\n'\n",
      " '상시 근로자 OO OIGS / 장애인 근로자 ,386명(1.54%)\\n'\n",
      " '*2018.12월 기준\\n'\n",
      " '\\n'\n",
      " \"'삼성전자 맞춤형 인재'로 성장하는데 있어서\\n\"\n",
      " '\\n'\n",
      " '비장애인과 장애인의 구분은 의미가 없다고 판단,\\n'\n",
      " '직무교육을 거쳐 고용된 장애인은 각 사업장에서\\n'\n",
      " '전기ㆍ전자,정보기술,기계디자인 분야에서근무 중\\n'\n",
      " '\\n'\n",
      " '| 의미\\n'\n",
      " '\\n'\n",
      " 'Ol\\n'\n",
      " '00\\n'\n",
      " '더\\n'\n",
      " 'roy\\n'\n",
      " '\\n'\n",
      " 'OH\\n'\n",
      " '\\n'\n",
      " 'KO\\n'\n",
      " '\\n'\n",
      " '|ESG\\n'\n",
      " '\\n'\n",
      " '로\\n'\n",
      " '10\\n'\n",
      " '0\\n'\n",
      " 'IN\\n'\n",
      " '\\n'\n",
      " 'iol\\n'\n",
      " '<\\n'\n",
      " '(=)\\n'\n",
      " 'ol\\n'\n",
      " 'N\\n'\n",
      " '‘eo\\n'\n",
      " '\\n'\n",
      " '‘eo\\n'\n",
      " '\\n'\n",
      " '| 기업의 장애인 고용 이점 |\\n'\n",
      " '\\n'\n",
      " '=\\n'\n",
      " '\\n'\n",
      " 'B iB\\n'\n",
      " '\\n'\n",
      " 'of\\n'\n",
      " '\\n'\n",
      " '지속\\n'\n",
      " '\\n'\n",
      " 'ro\\n'\n",
      " '\\n'\n",
      " '20 10\\n'\n",
      " '비사\\n'\n",
      " '더\\n'\n",
      " '\\n'\n",
      " '™ <b\\n'\n",
      " '\\n'\n",
      " '기업의 사회적\\n'\n",
      " '책임ㆍ미행\\n'\n",
      " '포춘지 선정\\n'\n",
      " '\\n'\n",
      " '(에) S S    100대 기업의 다양성 관리 분석\\n'\n",
      " '\\n'\n",
      " '사회전체의 행복과 복지 수준은\\n'\n",
      " '\\n'\n",
      " '그 사회에서 가장 소외되거나 배제된 약자의 행복과 복지수준에 의해 결정된다.\\n'\n",
      " '즉, 사회적으로 가장 열악한 처지에 있는 소득계층의 복지를 극대화 하는\\n'\n",
      " '\\n'\n",
      " '분배가 최적 재분배이다.\\n'\n",
      " '\\n'\n",
      " '최소 수혜자에게 최대의 이득이 될 때,\\n'\n",
      " '\\n'\n",
      " '이러한 불평등은 오히려 정의로운 것으로 정당화될 수 있다.\\n'\n",
      " '\\n'\n",
      " '_ 존 롤스, 정의론(^ Theory of Justice) 중\\n'\n",
      " '\\n'\n",
      " '기업의\\n'\n",
      " '장애인 고용이\\n'\n",
      " '\\n'\n",
      " '가지는\\n'\n",
      " '정당성의 논리\\n'\n",
      " '\\n'\n",
      " '무리사회 구성원 모두 안전하고 행복하게 살기 위해서는\\n'\n",
      " \"'기회`의 평등과 함께 '조건의 평등이 | 가주머저마티 함\\n\"\n",
      " '\\n'\n",
      " '개\\n'\n",
      " '\\n'\n",
      " '조건의 평등\\n'\n",
      " 'B.…e 장애인 근로자\\n'\n",
      " '\\n'\n",
      " '이 Ele\\n'\n",
      " '\\n'\n",
      " \"장애무'라는 호칭 바꾸기부터 시작\\n\"\n",
      " '\\n'\n",
      " '2018년부터 모든 현장 직원 대상으로\\n'\n",
      " '\\n'\n",
      " '직장내장애인인식개선교육을시행하는등\\n'\n",
      " '장애인직원이장기간근무할수 있는 여건마련\\n'\n",
      " '\\n'\n",
      " '장별 멘토를 지정해 현장\\n'\n",
      " '을\\n'\n",
      " 'o\\n'\n",
      " '\\n'\n",
      " '매장\\n'\n",
      " '잘 적응하도록 지원\\n'\n",
      " '\\n'\n",
      " '지점의 인사담당자가 정기면\\n'\n",
      " '고충 처리\\n'\n",
      " '\\n'\n",
      " '장애인 근로자 ＊\\n'\n",
      " '178\\n'\n",
      " '\\n'\n",
      " '상시 근로자\\n'\n",
      " '5503\\n'\n",
      " 'AIS] 가이 하한을 강조\\n'\n",
      " '트\\n'\n",
      " '장애인직무 개발노력으로                볼리 어가 아름\\n'\n",
      " '\\n'\n",
      " '1년 만에 고용률 성장\\n'\n",
      " '\\n'\n",
      " '함께 일하는 동료\\n'\n",
      " '\\n'\n",
      " '미해하기\\n'\n",
      " '\\n'\n",
      " 'At\\n'\n",
      " '\\n'\n",
      " '장애 정의 바로 알기\\n'\n",
      " '장애, 제대로 알아야 이해할 수 있습니다\\n'\n",
      " '\\n'\n",
      " 'UNZonel 2] BSF      장애인이란 다양 양한 장벽들로\\n'\n",
      " 'ANZ             사회에 참여하는 것\\n'\n",
      " '=\\n'\n",
      " '\\n'\n",
      " '감각적 손상을 가진\\n'\n",
      " '\\n'\n",
      " 'Lae\\n'\n",
      " '\\n'\n",
      " '인해, CHE 사람과 동등하게\\n'\n",
      " '\\n'\n",
      " 'fon]\\n'\n",
      " '것을 방해받는 장기간의 신체적, 정신적, 지적,\\n'\n",
      " '사람을 포함한다.\\n'\n",
      " '\\n'\n",
      " '장애인복지법\\n'\n",
      " '\\n'\n",
      " 'A\\n'\n",
      " '=\\n'\n",
      " '=\\n'\n",
      " '\\n'\n",
      " '장애인은 신체적-정신적 장애로 인하여                          장애인이란 신체 또는 정신상의 장매로\\n'\n",
      " '오랫동안 일상 및 사회생활에                           장기간에 걸쳐 직업생활에\\n'\n",
      " '상당한 제약을 받는 자\\n'\n",
      " '\\n'\n",
      " '상당한 제약을 받는 자\\n'\n",
      " '당신은 자신에게 어떤 문제가 있는지\\n'\n",
      " 'Sos 수 있습니까?\\n'\n",
      " '\\n'\n",
      " '청각상의 문제 때문에 SAS 사람들과\\n'\n",
      " '\\n'\n",
      " 'owe\\n'\n",
      " '\\n'\n",
      " 'JAAS 하는 데 어려움이 있습니까?\\n'\n",
      " '\\n'\n",
      " '당신의 건강문제나 장애가 버스로\\n'\n",
      " '여행하거나 이동하는 것을 어렵게 하나요?\\n'\n",
      " '\\n'\n",
      " '개인의 문제에서 사회구조의 문제로\\n'\n",
      " '\\n'\n",
      " '사회적 관점\\n'\n",
      " '환경적 책임\\n'\n",
      " 'Y SANZ 사회에 어떤 문제가 있는지\\n'\n",
      " '\\n'\n",
      " '것\\n'\n",
      " 'Jz\\n'\n",
      " '\\n'\n",
      " '|S\\n'\n",
      " '줄 수 있습니까?\\n'\n",
      " '\\n'\n",
      " 'Jf 사람들이 당신과 대화하는 SAS\\n'\n",
      " '지니지 못해, 당신은 사람들과\\n'\n",
      " '의사소통 하는데 어려움이 있습니까?\\n'\n",
      " '\\n'\n",
      " '부적   TOMI 설계된 버스가 당신이\\n'\n",
      " '그것을 이용하는데 어려움을\\n'\n",
      " '발생시키나요?\\n'\n",
      " '\\n'\n",
      " '/ 관점이 바뀌면 해결책도 바낌니다\\n'\n",
      " '장애유형의 이해\\n'\n",
      " '\\n'\n",
      " '우리나라는 15개의 잠애유형을 법적으로\\n'\n",
      " '정하고 있습니다\\n'\n",
      " '\\n'\n",
      " '신체적 장애\\n'\n",
      " '2   om |\\n'\n",
      " '국가마다 다른\\n'\n",
      " '비조                               브장\\n'\n",
      " '|        외부 장애        |.        내부 장애        |                      장애인 인정 '\n",
      " '범주\\n'\n",
      " '지체장애 청각장애            신장잠매 호흡기장애\\n'\n",
      " '뇌병변장애 언어장애            심장장애 장루/요루장애                                  미국\\n'\n",
      " '알코올 중독\\n'\n",
      " '시각잠매 안면잠매             간장매 뇌전증잠애\\n'\n",
      " '스웨덴\\n'\n",
      " '의사소통이 어려운\\n'\n",
      " '외국 이민자\\n'\n",
      " '정신적 장애\\n'\n",
      " '발달 장애                               정신 장애\\n'\n",
      " 'e                            @    e                            @\\n'\n",
      " '지적장애             정신장애\\n'\n",
      " '\\n'\n",
      " '자폐섬장애\\n'\n",
      " '\\n'\n",
      " '장애유형의 이해\\n'\n",
      " '\\n'\n",
      " '우리는 함께 살아가고 있습니다\\n'\n",
      " '\\n'\n",
      " '우리나라 장애인 인                     :                     현황 (2021년 기준)\\n'\n",
      " '45.1%\\n'\n",
      " '전체 인구대비 o--.---.\\n'\n",
      " '장애인 인구     <“\\n'\n",
      " '2 645,0003                Q                                                  '\n",
      " '15.6%\\n'\n",
      " '\\n'\n",
      " '5 le  QR         _ 95. 9.4.x\\n'\n",
      " 'ia\\n'\n",
      " '\\n'\n",
      " '지체장애 첨각장애 시각장애 뇌병변장애\\n'\n",
      " '\\n'\n",
      " '우리나라 장애인 SASS 5% 내외 Benes aera bss\\n'\n",
      " '\\n'\n",
      " 'OECD 국가                                           24.5%\\n'\n",
      " '\\n'\n",
      " '한 =  5ㅁ5%내외\\n'\n",
      " '장애인에 대한 시각과 태도\\n'\n",
      " '\\n'\n",
      " '대중매제에서 만나는 장애인의 모습\\n'\n",
      " '\\n'\n",
      " 'o Nae 동정\\n'\n",
      " '장애 때문에 어려움과 비참함을 A\\n'\n",
      " '사람들의 PSS 통해 시혜와 SS\\n'\n",
      " '\\n'\n",
      " '불러일으킴\\n'\n",
      " '\\n'\n",
      " 'wo tr\\n'\n",
      " '\\n'\n",
      " '봉사\\n'\n",
      " '\\n'\n",
      " '장애인을 위해 봉사하는 OlLSO|\\n'\n",
      " '\\n'\n",
      " '아름다운 이야기들을 통해, 삭막한\\n'\n",
      " '\\n'\n",
      " '사회에서 인간미가 살아있음을 보여줌\\n'\n",
      " '책임을 오롯이 장애를 가진\\n'\n",
      " '\\n'\n",
      " '개인에게 떠넘기는 결과를 SS\\n'\n",
      " '\\n'\n",
      " '장애인은 늘 불쌍하고\\n'\n",
      " '\\n'\n",
      " '우리 사회 구조가 바뀌어야 한다는\\n'\n",
      " '\\n'\n",
      " '생각을 약화시킴\\n'\n",
      " '\\n'\n",
      " '도움이 필요한 존재로 인식시킴\\n'\n",
      " '\\n'\n",
      " '잠애인을 보는 시각에는 특별함이 아닌,\\n'\n",
      " '평범함이 필요합니다\\n'\n",
      " '장애인을잘대하는\\n'\n",
      " '\\n'\n",
      " '모든 시각장애인은\\n'\n",
      " '\\n'\n",
      " '첨자를 안다?\\n'\n",
      " '\\n'\n",
      " '장매인고용의 법적, 제도적 내용\\n'\n",
      " '\\n'\n",
      " '는 사업주는 해당 사업체 근로자 종수의 2%내지 3%에\\n'\n",
      " '근로자를 의무적으로 고용해야 하는 제도\\n'\n",
      " '\\n'\n",
      " '*의무고용대상 : 국가ㆍ지방자치단체, 상시근로자 SOS 이상을 고용하고 있는 사업주\\n'\n",
      " '\\n'\n",
      " '(×)  장애인 의무고용률\\n'\n",
      " 'Ci) 달섬못할경무\\n'\n",
      " '\\n'\n",
      " 'fel        의무고용률 이상\\n'\n",
      " '\\n'\n",
      " 'RY 고용한사업주\\n'\n",
      " '장매인고용의 법적, 제도적 내용\\n'\n",
      " '\\n'\n",
      " '101\\n'\n",
      " '\\n'\n",
      " '시종\\n'\n",
      " '일은\\n'\n",
      " '\\n'\n",
      " '애인 스스로 자립할 권리\\n'\n",
      " '\\n'\n",
      " '전 AHO! OJAI\\n'\n",
      " '“a “0 I\\n'\n",
      " '\\n'\n",
      " '01\\n'\n",
      " '<\\n'\n",
      " '이\\n'\n",
      " 'K\\n'\n",
      " 'nm\\n'\n",
      " 'uu\\n'\n",
      " '~\\n'\n",
      " 'It\\n'\n",
      " 'KO\\n'\n",
      " 'ol\\n'\n",
      " '~\\n'\n",
      " '\\n'\n",
      " '애인고용의 법적, 제도적 내용\\n'\n",
      " '\\n'\n",
      " 'KO\\n'\n",
      " '\\n'\n",
      " '의무고용사업체 장애인 고용현황\\n'\n",
      " '\\n'\n",
      " '는\\n'\n",
      " '\\n'\n",
      " '래\\n'\n",
      " '\\n'\n",
      " '0\\n'\n",
      " '00\\n'\n",
      " '\\n'\n",
      " '매\\n'\n",
      " 'It\\n'\n",
      " '\\n'\n",
      " '3e\\n'\n",
      " 'co\\n'\n",
      " '\\n'\n",
      " 'J.\\n'\n",
      " '\\n'\n",
      " '3.4. 3.4\\n'\n",
      " '\\n'\n",
      " '3.4%\\n'\n",
      " '\\n'\n",
      " '2020      2021      ㅁ2022\\n'\n",
      " '\\n'\n",
      " '2019\\n'\n",
      " '\\n'\n",
      " '31, 3x\\n'\n",
      " '\\n'\n",
      " '3.1%\\n'\n",
      " '\\n'\n",
      " '3. ly.\\n'\n",
      " '\\n'\n",
      " '2020      2021      ㅁ2022\\n'\n",
      " '\\n'\n",
      " '2019\\n'\n",
      " '법   도적\\n'\n",
      " 'Olsk & OIL Ol\\n'\n",
      " '그 ey 일터\\n'\n",
      " '\\n'\n",
      " '내용\\n'\n",
      " '\\n'\n",
      " '만듭니다\\n'\n",
      " '\\n'\n",
      " '장애인구와 전체인구의 경제활동상태 비교\\n'\n",
      " '\\n'\n",
      " '| 2022년 상반기 |\\n'\n",
      " '\\n'\n",
      " '64.9\\n'\n",
      " '\\n'\n",
      " '| 제도\\n'\n",
      " '\\n'\n",
      " '(=)\\n'\n",
      " '7\\n'\n",
      " 'Pi\\n'\n",
      " '\\n'\n",
      " '사업주 Al\\n'\n",
      " '\\n'\n",
      " '사루 서비스\\n'\n",
      " '\\n'\n",
      " '|정 서비스\\n'\n",
      " '\\n'\n",
      " '더\\n'\n",
      " '040\\n'\n",
      " 'r]\\n'\n",
      " '\\n'\n",
      " '사전 서비스\\n'\n",
      " '\\n'\n",
      " '원\\n'\n",
      " '\\n'\n",
      " '작업편의지\\n'\n",
      " '근로지원인,\\n'\n",
      " '보조공학기기\\n'\n",
      " '\\n'\n",
      " '원\\n'\n",
      " '\\n'\n",
      " '관리비\\n'\n",
      " '\\n'\n",
      " '=       SX\\n'\n",
      " '장애인고용시설 SAWS\\n'\n",
      " '\\n'\n",
      " '고\\n'\n",
      " '\\n'\n",
      " 'to\\n'\n",
      " '\\n'\n",
      " '상관\\n'\n",
      " '편의지원\\n'\n",
      " '\\n'\n",
      " '대\\n'\n",
      " '\\n'\n",
      " '개선\\n'\n",
      " '| 제도\\n'\n",
      " '\\n'\n",
      " '호\\n'\n",
      " '3\\n'\n",
      " '—\\n'\n",
      " '\\n'\n",
      " '사업주 Al\\n'\n",
      " '\\n'\n",
      " '기\\n'\n",
      " 'N\\n'\n",
      " 'mi\\n'\n",
      " '09\\n'\n",
      " 'au\\n'\n",
      " 'nN\\n'\n",
      " 'in\\n'\n",
      " 'ri\\n'\n",
      " '4\\n'\n",
      " '[10\\n'\n",
      " '나\\n'\n",
      " 'KO\\n'\n",
      " '00\\n'\n",
      " '더\\n'\n",
      " '\\n'\n",
      " 'x0\\n'\n",
      " '\\n'\n",
      " '10\\n'\n",
      " '\\n'\n",
      " 'TT\\n'\n",
      " '\\n'\n",
      " '[^\\n'\n",
      " '\\n'\n",
      " 'x0\\n'\n",
      " 'JO\\n'\n",
      " '10\\n'\n",
      " '\\n'\n",
      " 'TT\\n'\n",
      " '\\n'\n",
      " '[^\\n'\n",
      " '\\n'\n",
      " '3ㅁ만원\\n'\n",
      " '\\n'\n",
      " '(0 ㅁ\\n'\n",
      " '00 미\\n'\n",
      " '\\n'\n",
      " '20 =\\n'\n",
      " 'Ko ㅁ\\n'\n",
      " 'Ko 트\\n'\n",
      " '\\n'\n",
      " '의무고용률\\n'\n",
      " '조과 사업체\\n'\n",
      " '\\n'\n",
      " 'Li\\n'\n",
      " '~\\n'\n",
      " '<b\\n'\n",
      " 'K\\n'\n",
      " 'fH\\n'\n",
      " '브\\n'\n",
      " 'x\\n'\n",
      " '20\\n'\n",
      " '©\\n'\n",
      " '상시근로자 중\\n'\n",
      " '9 장애인 근로자수               장애인 는\\n'\n",
      " '(=)  Lae\\n'\n",
      " '\\n'\n",
      " 'e 10인 이상             i  309% 이상\\n'\n",
      " '\\n'\n",
      " '자회사형 표준사업장   cosine\\n'\n",
      " '\\n'\n",
      " '자회사의 장애인근로자를 모회사의 장애인고용의무인원으로 산입하여 부담금 감면\\n'\n",
      " '\\n'\n",
      " '“국내 1S 자회사형 °°\\n'\n",
      " '\\n'\n",
      " '——s ed wil > 27 ;소 / -장애인표준사업장\\n'\n",
      " '\\n'\n",
      " '”이미지 출처 : 포스코휴먼스\\n'\n",
      " '\\n'\n",
      " '| 제도\\n'\n",
      " '\\n'\n",
      " '©\\n'\n",
      " '토그\\n'\n",
      " 'Pi\\n'\n",
      " '\\n'\n",
      " '사업주 Al\\n'\n",
      " '\\n'\n",
      " '공학기기 지원\\n'\n",
      " '\\n'\n",
      " 'KI\\n'\n",
      " '\\n'\n",
      " '보\\n'\n",
      " '\\n'\n",
      " 'OF!\\n'\n",
      " '\\n'\n",
      " '01\\n'\n",
      " '이\\n'\n",
      " '\\n'\n",
      " '근로지\\n'\n",
      " '\\n'\n",
      " '는 사업주,\\n'\n",
      " '\\n'\n",
      " '|\\n'\n",
      " '\\n'\n",
      " '0\\n'\n",
      " '\\n'\n",
      " '4인 이하의 근로자를 고용하고 있는\\n'\n",
      " '장애인 사업주 및 근로자\\n'\n",
      " '\\n'\n",
      " '을 고용하고 있거나 고용\\n'\n",
      " '\\n'\n",
      " 'ㅇ\\n'\n",
      " 'ra\\n'\n",
      " '\\n'\n",
      " 'OH\\n'\n",
      " '\\n'\n",
      " 'At\\n'\n",
      " '(=\\n'\n",
      " '\\n'\n",
      " '중증장애인\\n'\n",
      " '1일 8시간, 주 40시간 이내\\n'\n",
      " '\\n'\n",
      " '원\\n'\n",
      " '\\n'\n",
      " '이동 지\\n'\n",
      " '\\n'\n",
      " '자동차 개소\\n'\n",
      " '\\n'\n",
      " '인간으로서 존엄과 가치를 가지며\\n'\n",
      " '\\n'\n",
      " '=      [=]\\n'\n",
      " '행복을 ATS 권리를 가진다\\n'\n",
      " '\\n'\n",
      " '장애인은 인간의 존엄과 가치를 가지며 행복을 추구할 권리를 가진다.\\n'\n",
      " '장애인은 건전한 사회 구성원으로 책임 있는 삶을 살아가며\\n'\n",
      " '\\n'\n",
      " '자신의 능력을 개발하여 자립하도록 노력하여야 한다.\\n'\n",
      " '\\n'\n",
      " '국가와 사회는 헌법과 국제연합의 장애인 권리선언의 정신에 따라\\n'\n",
      " '장애인의 인권을 보호하고 완전한 사회참여와 평등을 이루어\\n'\n",
      " '\\n'\n",
      " '더불어 살아가는 사회를 만들기 위한 FAS 환경을 조성하여야 한다.\\n'\n",
      " '\\n'\n",
      " '_ 장애인 인권헌장 무\\n'\n",
      " '\\n'\n",
      " '누구나 예외 없이 보장되어야 하는 인권\\n'\n",
      " 'LIN 장애인 권리협약\\n'\n",
      " '\\n'\n",
      " '장애는 점진적으로 변화하는 개념이며,\\n'\n",
      " '손상을 지닌 사람과 그들이 다른 사람과 동등하게 사회에\\n'\n",
      " '완전하고 효과적으로 참여하는 것을 저해하는 태도 및\\n'\n",
      " '환경적인 장벽 간의 상호작용으로부터 기인된다는 것을 인정한\\n'\n",
      " '\\n'\n",
      " '_ 0씨장애인 권리협약 전문(6)항\\n'\n",
      " '\\n'\n",
      " 'jt\\n'\n",
      " '\\n'\n",
      " '출처 : 김형식(2008) 10장애인권리협약과 장애인의 시민적 권리\\n'\n",
      " '사람의 인권\\n'\n",
      " '\\n'\n",
      " '모든\\n'\n",
      " '\\n'\n",
      " '장애인 차별금지법\\n'\n",
      " '\\n'\n",
      " '자이를 넘어 차별 없는 세삼으로!\\n'\n",
      " '\\n'\n",
      " '장애인차별금지법 (2007.4월 제정)\\n'\n",
      " '\\n'\n",
      " '장애를 이유로\\n'\n",
      " '\\n'\n",
      " '3\\n'\n",
      " '\\n'\n",
      " '=]\\n'\n",
      " 'io\\n'\n",
      " '\\n'\n",
      " '흐\\n'\n",
      " '\\n'\n",
      " '재화와 용역의                                                                   '\n",
      " '가족ㆍ가정ㆍ복지시설\\n'\n",
      " '제공및 이용\\n'\n",
      " '\\n'\n",
      " 'ss\\n'\n",
      " '(<=2000(\\n'\n",
      " '\\n'\n",
      " '사법-행정절차및\\n'\n",
      " '서비스와참정권\\n'\n",
      " '\\n'\n",
      " '장애여성-장애아동\\n'\n",
      " '-정신적장애\\n'\n",
      " '|법\\n'\n",
      " '3\\n'\n",
      " 'HA\\n'\n",
      " '_\\n'\n",
      " 'la!\\n'\n",
      " 'Pe\\n'\n",
      " '\\n'\n",
      " 'Pd\\n'\n",
      " '\\n'\n",
      " '장애인을                형식상으로 공  res 적용했\\n'\n",
      " 'Hols         거부하거                 용잇\\n'\n",
      " '전드                         으\\n'\n",
      " '보기 정당한\\n'\n",
      " '하게 one oe              a   생하였다면 이는 간접차별\\n'\n",
      " '불   대우\\n'\n",
      " '하는  ion\\n'\n",
      " 'pl 7\\n'\n",
      " '말합 다\\n'\n",
      " 'LIC q\\n'\n",
      " '[\\n'\n",
      " '현\\n'\n",
      " '식상으로\\n'\n",
      " ' DAS\\n'\n",
      " '“plataeiich\\n'\n",
      " '하였\\n'\n",
      " '다\\n'\n",
      " '이는 one\\n'\n",
      " 'tS at\\n'\n",
      " '[전  람\\n'\n",
      " '접차별  sie\\n'\n",
      " 'c  !에거\\n'\n",
      " 'ste |=\\n'\n",
      " '합니 더\\n'\n",
      " '다\\n'\n",
      " '\\n'\n",
      " '출처 :\\n'\n",
      " '국7\\n'\n",
      " '|인권\\n'\n",
      " '|으\\n'\n",
      " '위원\\n'\n",
      " '원회\\n'\n",
      " '장애인 차별금지법\\n'\n",
      " '\\n'\n",
      " '자이를 넘어 차별 없는 세삼으로!\\n'\n",
      " '\\n'\n",
      " '에 의한 차별                              광고에 의한 차별\\n'\n",
      " '\\n'\n",
      " '\"^ slop\\n'\n",
      " '\\n'\n",
      " \"Aon                 』, | 우' 의 느이\\n\"\n",
      " 'aula}? |                . 사자 See!\\n'\n",
      " '디보 Jae                             시\\n'\n",
      " '\\n'\n",
      " 'ins ar\\n'\n",
      " '\\n'\n",
      " '과도한 부담이나 현저히 곤란한 사정과 같은                                                    '\n",
      " '광고의 내용이 장애인에 대한 배제ㆍ거부 등\\n'\n",
      " '정당한 이유 없이 장애인에게 편의시설이나                                                     '\n",
      " '불리한 대우를 나타내는 경우\\n'\n",
      " '서비스 등의 ASS 거부하는 경우를 말합니다.                                                  '\n",
      " '이는 광고에 의한 차별에 해당됩니다.\\n'\n",
      " '\\n'\n",
      " '줄처 : 국가인권위원회\\n'\n",
      " '정당한 편의제공 거부에 의한 차별\\n'\n",
      " '\\n'\n",
      " '정당한 편의제공으로 장애인의 동등한 활동 참여\\n'\n",
      " '\\n'\n",
      " '0  06  EA\\n'\n",
      " '\\n'\n",
      " '장애인차별금지법 Alas\\n'\n",
      " '\\n'\n",
      " \"정당한 사유 없이 장애인에 대하여 정당한 편의 제공을 거부하는 경우'를 차별행위의 한 유형으로 규정\\n\"\n",
      " '\\n'\n",
      " '-1항-\\n'\n",
      " 'HO} =} 함은 장애인이 장애가 없는 사람과 동등하게 같은 활동에 참여할 수 있도록\\n'\n",
      " '장애인의 성별, 장애의 유형 및 정도, 특성 등을 고려한\\n'\n",
      " '편의시설ㆍ설비ㆍ도구ㆍ서비스 등 인적ㆍ물적 제반 수단과 조치를 말한다\\n'\n",
      " '\\n'\n",
      " '-2항-\\n'\n",
      " '\\n'\n",
      " '정당\\n'\n",
      " '\\n'\n",
      " 'rst\\n'\n",
      " '\\n'\n",
      " '물적인 지원, 직무재배지\\n'\n",
      " '\\n'\n",
      " '시설장비의 설치나 개조,                               류가제도나\\n'\n",
      " '출입구 및 경사로 설치                 작업장 방침 변경\\n'\n",
      " '\\n'\n",
      " '제도개선\\n'\n",
      " '\\n'\n",
      " '지체장애\\n'\n",
      " '\\n'\n",
      " '계단 이용이 어렵다면,\\n'\n",
      " '경사로를 설치하여 출입이 가능하도록 함        모니터에 SICH 독서기걸지\\n'\n",
      " '\\n'\n",
      " '     ues\\n'\n",
      " '\\n'\n",
      " 'HAAS Ol 제한에 있을 시,                                                       근무시간 '\n",
      " '중\\n'\n",
      " '수어통역사를 보조인으로 배치하여                           투석이 필요한 경우, 근무시간\\n'\n",
      " '의사소통이 필요한 직무를 가능하게 함                            변경하여 근무가 가능하도록\\n'\n",
      " '\\n'\n",
      " 'ot Mio\\n'\n",
      " '차별\\n'\n",
      " '\\n'\n",
      " '|\\n'\n",
      " '\\n'\n",
      " 'iol\\n'\n",
      " 'Ol\\n'\n",
      " '\\n'\n",
      " '|제공 거부에\\n'\n",
      " '\\n'\n",
      " 'ol\\n'\n",
      " '터\\n'\n",
      " 'iol\\n'\n",
      " '140\\n'\n",
      " 'KO\\n'\n",
      " '\\n'\n",
      " '|\\n'\n",
      " '\\n'\n",
      " '『\\n'\n",
      " '\\n'\n",
      " '4\\n'\n",
      " '\\n'\n",
      " '소절 테이블 So\\n'\n",
      " '\\n'\n",
      " '엘리베이터, 높낮이\\n'\n",
      " '시설장비가 필요\\n'\n",
      " '\\n'\n",
      " '사로,\\n'\n",
      " '\\n'\n",
      " '견\\n'\n",
      " 'ㅇ=\\n'\n",
      " '\\n'\n",
      " '여\\n'\n",
      " '비\\n'\n",
      " '뜨\\n'\n",
      " '도\\n'\n",
      " 'iol\\n'\n",
      " '\\n'\n",
      " '00\\n'\n",
      " 'Ki\\n'\n",
      " '\\n'\n",
      " 'TH\\n'\n",
      " 'ii\\n'\n",
      " '매\\n'\n",
      " 'Tr\\n'\n",
      " '|\\n'\n",
      " '\\n'\n",
      " 'S&S\\n'\n",
      " '\\n'\n",
      " 'F\\n'\n",
      " '\\n'\n",
      " '11\\n'\n",
      " '\\n'\n",
      " '패ㅋ\\n'\n",
      " '|지중증인턴제\\n'\n",
      " '\\n'\n",
      " '어서고\\n'\n",
      " '\\n'\n",
      " 'KF\\n'\n",
      " '\\n'\n",
      " '프\\n'\n",
      " '프로그램\\n'\n",
      " '=]\\n'\n",
      " '\\n'\n",
      " '|\\n'\n",
      " '\\n'\n",
      " 'T=\\n'\n",
      " 'Le\\n'\n",
      " '\\n'\n",
      " '1고\\n'\n",
      " 'Sia lal\\n'\n",
      " '지운\\n'\n",
      " '\\n'\n",
      " '!턴근\\n'\n",
      " '\\n'\n",
      " 'ㅇ\\n'\n",
      " 'ra\\n'\n",
      " '\\n'\n",
      " '2\\n'\n",
      " '\\n'\n",
      " '|\\n'\n",
      " '\\n'\n",
      " '증장애온\\n'\n",
      " '\\n'\n",
      " '장애\\n'\n",
      " '\\n'\n",
      " '능력\\n'\n",
      " '에따른 사업체소개\\n'\n",
      " '\\n'\n",
      " 'nS\\n'\n",
      " 'i\\n'\n",
      " '\\n'\n",
      " '|\\n'\n",
      " '\\n'\n",
      " 'K\\n'\n",
      " 'IN\\n'\n",
      " '=\\n'\n",
      " '— |\\n'\n",
      " '\\n'\n",
      " '고\\n'\n",
      " '=\\n'\n",
      " 'ry\\n'\n",
      " '\\n'\n",
      " '| a\\n'\n",
      " '\\n'\n",
      " '취업을 희망하는\\n'\n",
      " 'Cc\\n'\n",
      " '\\n'\n",
      " '만 IBA 이상 GSA] 이하의 장애인\\n'\n",
      " '\\n'\n",
      " '단겨\\n'\n",
      " '\\n'\n",
      " '애인 취업성\\n'\n",
      " '\\n'\n",
      " '제도\\n'\n",
      " '\\n'\n",
      " '장\\n'\n",
      " '\\n'\n",
      " '으\\n'\n",
      " '=\\n'\n",
      " '\\n'\n",
      " '애인 지\\n'\n",
      " '\\n'\n",
      " '『\\n'\n",
      " '\\n'\n",
      " '<0\\n'\n",
      " '\\n'\n",
      " '장애인 근로자 상시 20S 미상\\n'\n",
      " '\\n'\n",
      " '2\\n'\n",
      " '\\n'\n",
      " '620\\n'\n",
      " '\\n'\n",
      " '©\\n'\n",
      " '\\n'\n",
      " 'Ie\\n'\n",
      " '\\n'\n",
      " 'I\\n'\n",
      " '\\n'\n",
      " 'i\\n'\n",
      " 'Rl\\n'\n",
      " 'xd\\n'\n",
      " 'K\\n'\n",
      " 'fe)\\n'\n",
      " '\\n'\n",
      " 'ㄱㄱ\\n'\n",
      " '\\n'\n",
      " '|\\n'\n",
      " '한국장애인고용공단   ： i\\n'\n",
      " '\\n'\n",
      " '기업의 사회적 가치 실현의 첫걸음,\\n'\n",
      " '\\n'\n",
      " 'sp] 하면 깊이 보입니다\\n'\n",
      " '\\n'\n",
      " '감사합니다\\n'\n",
      " '\\n')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pp\n",
    "pp(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text saved to extracted_text.txt\n"
     ]
    }
   ],
   "source": [
    "# 텍스트를 txt 파일로 저장\n",
    "def save_text_to_file(text, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "# 저장할 파일 경로 설정\n",
    "txt_file_path = 'extracted_text.txt'\n",
    "save_text_to_file(pdf_text, txt_file_path)\n",
    "print(f\"Text saved to {txt_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "읽히긴 하지만 오타도 많고 의미를 알아보기가 쉽지 않았다.  \n",
    "이미지 전처리를 통해 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지 전처리\n",
    "def preprocess_image(image):\n",
    "    # 이미지를 그레이스케일로 변환\n",
    "    gray = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
    "    # 이진화\n",
    "    _, binary_image = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    # 노이즈 제거\n",
    "    processed_image = cv2.medianBlur(binary_image, 3)\n",
    "    return Image.fromarray(processed_image)\n",
    "\n",
    "\n",
    "# 각 페이지에서 텍스트 추출\n",
    "def ocr_from_pdf(pages):\n",
    "    text = ''\n",
    "    for num, page in enumerate(pages):\n",
    "        # 이미지를 일시적으로 저장\n",
    "        temp_image_path = f\"temp_page_{num+1}.png\"\n",
    "        processed_page = preprocess_image(page)\n",
    "        processed_page.save(temp_image_path, 'PNG')\n",
    "        \n",
    "        # 이미지에서 텍스트 추출\n",
    "        page_text = pytesseract.image_to_string(Image.open(temp_image_path), lang='kor+eng')\n",
    "        text += page_text\n",
    "        \n",
    "        # 일시적 이미지 파일 삭제\n",
    "        os.remove(temp_image_path)\n",
    "        \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "장매유형별 모듈\n",
      "\n",
      "한국장애인고용공단 FP\n",
      "\n",
      "Contents\n",
      "\n",
      "0. 장애이해하7|(공통)\n",
      "1. 일터 엿보기\n",
      "\n",
      "2. 미해하기\n",
      "\n",
      "3. 함께 일하7|\n",
      "\n",
      "4. 71억해주세요/\n",
      "\n",
      "5. 마무리\n",
      "\n",
      "0. St0H 이해하기                                                                          한국장야인고8공단 FL\n",
      "\n",
      "장매인복지법\n",
      "\n",
      "장애인은 신체적ㆍ정신적 장애로 인하여\n",
      "\n",
      "(0\n",
      "오랫동안 일상 및 사회생활에\n",
      "상당한 제약을 받는 자\n",
      "\n",
      "장애인이란 신체 또는 정\n",
      "장기간에 걸쳐 직업생활에\n",
      "상당한 제약을 받는 자\n",
      "\n",
      "0. 장애 이해하기\n",
      "한국장애인고용공단\n",
      "\n",
      "ㆍ지체장애\n",
      ">뇌병변장애                                             끼적\n",
      "\n",
      "» 시각장애                                                강매\n",
      "\n",
      "0. Zt0H 이해하기                                                                          eagqensan AP\n",
      "\n",
      "장애등급제 폐지\n",
      "\n",
      "복/끼서비스 NAS 위한 장애인\n",
      "\n",
      "MOSES 장매정도로 변경\n",
      "\n",
      "ㆍ의학적 기준(1~6급)                       ㆍ심한 장애인(1~3급)\n",
      "ㆍ심하지 않은 장애인(4~6급)\n",
      "\n",
      "0. St0H 이해하기                                                                         한국장애인고8공단 FP\n",
      "\n",
      "AAA @\n",
      "\n",
      "록현황 / 20194 128 기준)\n",
      "\n",
      "0. St0H 이해하기                                                                          한국장야인고8공단 FL\n",
      "\n",
      "출생시원인\n",
      "14%\n",
      "\n",
      "원인불명 선전적원인 |\n",
      "54% —N%\n",
      "\n",
      "후천적 질환\n",
      "\n",
      "56.0%\n",
      "\n",
      "출처 : 2017년 장애인 실태조사\n",
      "\n",
      "누구도 장애인이 될 가능성에서 ASSN 않습니다\n",
      "\n",
      "0. 장애 이해하기                                                                          한국장애인고8강단 FAP\n",
      "\n",
      "장애개념\n",
      "\n",
      "66\n",
      "누구나 신체적인 SME\n",
      "장매인이 되는 것이 아니라\n",
      "사회에 의해 장애인이 될 수 있다             vd Hee\n",
      "\n",
      "World Health\n",
      "\n",
      "Organization\n",
      "세계장애보고서 WHO                                          99                   9\n",
      "\n",
      "0. 장애 이해하기\n",
      "한국장애인고8공단 FP\n",
      "\n",
      "—\n",
      "\n",
      "|\n",
      "\n",
      "국제표준화7|구(150)\n",
      "\n",
      "ACCESSIBLE\n",
      "ICON PROJECT\n",
      "\n",
      "인고용공단   f 1\n",
      "\n",
      "한국장애\n",
      "\n",
      "하기\n",
      "\n",
      "해\n",
      "\n",
      "장매 이\n",
      "\n",
      "0.\n",
      "\n",
      "단제의\n",
      "\n",
      "장애인 고용 의무\n",
      "\n",
      "=\n",
      "=\n",
      "20\n",
      "ㄷ\n",
      "ok\n",
      "~\n",
      "1\n",
      "\n",
      "0. St0H 이해하기                                                                          한국장야인고8공단 FL\n",
      "\n",
      "다양한 영역에서 장애인에 대한 AHA 금지, 비장애인과 동\n",
      "마련하7| 위해 정당한 편의제공 규정\n",
      "\n",
      "장애인이                         ㆍ제1장 총칙\n",
      "비장애인과 동일하게                       =\n",
      "ㆍ제2장 차별금지\n",
      "모든 인권과                   - 제1절 고용\n",
      "\n",
      "기본적 자유 향유            - 제2열 교육\n",
      "- 제3절 재화와 용역의 제공 및 이용\n",
      "- 제4절 사법ㆍ행정절차 및 서비스와 참정권\n",
      "- 제5절 모ㆍ부성권, 성 등\n",
      "모든 사회생활에                  - ASS 장애여성 및 장애아동 등\n",
      "잠며할 수 있도록               ㆍ제4장 장애인차별시정기구 및 권리구제 등\n",
      "ANS 생활환경 ASHE                              .\n",
      "ㆍ제5장 손해배상, 입증책임 등\n",
      "유형-무형의 적극적 조끼             HS BONES\n",
      "ㆍ제6장 벌칙\n",
      "\n",
      "0. St0H 이해하기                                                                          한국장야인고8공단 FL\n",
      "\n",
      "oA 직장 내 장매인의 인권, 장매인에 대한 자별금지\n",
      "\n",
      "시설-장비의 SAL * A\n",
      "\n",
      "\"SOHN B\n",
      "권리구제 등에 관한 FS, Ms\n",
      "\n",
      "장애인에 대한\n",
      "비장애인과 동\n",
      "^\n",
      "\n",
      "3\n",
      "\n",
      "0. 장애 이해하|\n",
      "\n",
      "직접자별\n",
      "\n",
      "정당한 편의\n",
      "제공 거부\n",
      "\n",
      "한국장애인고8공단 FP\n",
      "\n",
      "장애인의 SHE ASS 정당한 사유 없이\n",
      "\n",
      "제한:배제분리:거부 등에 의하여 불리하게 대하는 경우\n",
      "\n",
      "장애인에 대하여 형식상으로는 제한배께분리「거부 등에\n",
      "의하며 불리하게 대하끼 아니하끼만 정당한 사유 없이\n",
      "SOE TAS 아니하는 7|준을 적용함으로써\n",
      "\n",
      "장애인에게 불리한 결과를 조래하는 경우\n",
      "\n",
      "정당한 사유 없이 SOKO 대하여 정당한 편의제공*\n",
      "거부하는 경우\n",
      "\n",
      "*정당한편의 :장애인이 장애가 없는 사람과 동등하게 같은 활동에 참여할 수 있도록\n",
      "장애인의 성별 장애의 유형 및 정도 특성 SS 고려한 편의시설-설비-도구서비스 등\n",
      "\n",
      "인적ㆍ물적 제반 수단과 조치\n",
      "0. St0H 이해하기                                                                          한국장야인고8공단 FL\n",
      "\n",
      "정당한 사유 없이 장애인에 대한 제한배제ㆍ분리ㆍ거부 등\n",
      "불리한 대우를 표/\\|ㆍ조장하는 광고를 직접 행하거나 그러한\n",
      "광고를 허용-조장하는 경우, 이 경우 광고는 통삼적으로\n",
      "불리한 대우를 조장하는 광고효과가 있는 것으로 인정되는 행위\n",
      "\n",
      "aU | OHOIS 돕7| 위한 SHIM\n",
      "See 장애인을 대리동행하는 Atl 대하여 1~4의 행위를\n",
      "Ne           하는 경우\n",
      "\n",
      "보조견 또는\n",
      "장애인\n",
      "보조7|구에\n",
      "대한 자별\n",
      "\n",
      "보조견 또는 장애인 보조7|구 So] 정당한 ASS\n",
      "방해하거나 보조견 및 장애인 보조7|구 SS YO 하는\n",
      "자별행위\n",
      "\n",
      "1. 일터 엿보                                                                                                한국장애인고용공단 +7\n",
      "\n",
      "2. 미해하기                                                                          한국장애인고8공단 FP\n",
      "\n",
      "/시과장애란?\n",
      "\n",
      "S HO] 눈으로 들어와 SIMA 전달되는 과정 중\n",
      "어느 부위가 손상되어 발생하는 AMATO,\n",
      "/|야결손장애\n",
      "\n",
      "만국식 ASR 즉정된 AO!\n",
      "\n",
      "0.02 이하로 즉정되거나\n",
      "\n",
      "두 눈의 ANA 2분의 1 이상을 잃은 사람 등\n",
      "눈의 7|능에 문께가 있어 ANAS 잃거나\n",
      "\n",
      "시야 각도가 좁은 것을 Fe\n",
      "\n",
      "2. 미해하기                                                                         한국장야인고8공단 FL\n",
      "\n",
      "우리나라 시곽장애 인구\n",
      "\n",
      "뇌병변장애\n",
      "“우리나라 /|각장애 인구 ＊*                       248,308명\n",
      "\n",
      "25만명                                                     시곽장애\n",
      "\n",
      "정각장애\n",
      "411,749명\n",
      "\n",
      "끼제장애\n",
      "1,191,462명\n",
      "\n",
      "2021년 12월 말 보건복지부 장애인 등록현황\n",
      "\n",
      "2. 미해하기                                                                         한국장야인고8공단 FL\n",
      "\n",
      "18.7%\n",
      "\n",
      "SOM 않은 장애\n",
      "\n",
      "2. OloHOt7I                                                                                                 한국장애인고용공단 +7\n",
      "\n",
      "아무 것도 볼\n",
      "\n",
      "제가 MALE /|각장애인이라.\n",
      "\n",
      "책 ZS NOR 수 있을까요?\n",
      "\n",
      "시팡이도 없이 잘 걸어 다니는데,\n",
      "장애인?\n",
      "\n",
      "2. 미해하기                                                                         한국장애인고단 FP\n",
      "\n",
      "점자블록0| 노란색인 이유?\n",
      "\n",
      "httos://m.post.naver.com/viewer/postView.naver 2volumeNo=17155870&memberNo=2993146\n",
      "\n",
      "2. 미해하기\n",
      "\n",
      "시곽장매에 대한 오해 1\n",
      "\n",
      "oY /|곽장애인 중 MBS 10명 중 3명\n",
      "나머지 7명은 NAS 장애\n",
      "\n",
      "SA 백내장, 녹내장, 이물질 a\n",
      "시과손상으로 인한 장매로\n",
      "전혀 볼 수 없는 THE 소수,\n",
      "대부분 명암이나 형태 구분 가능\n",
      "\n",
      "2. 미해하기                                                                         한국장야인고8공단 FL\n",
      "\n",
      "시곽장애에 대한 오해 2\n",
      "\n",
      "2. 미해하기                                                                          한국장애인고용공단 FP\n",
      "\n",
      "출처 :2020장애인실태소사보조서\n",
      "\n",
      "2. 미해하기                        한국장애인고8강단 FAP\n",
      "\n",
      "/|각장애 52287171\n",
      "\n",
      "점까정보단말7|                독/서확대7|                   SSN\n",
      "\n",
      "ㆍ점자와 음성을 통해 문서의          ㆍ저시력시각장애인 또는            ㆍ음성으로 녹음이 된\n",
      "출력과 인터넷을 자유롭게             노인이 문자를 읽을 수                책 파일이나, 텍스트로만\n",
      "이용할 수 있도록 만든                 있도록 확대시켜 주는 장치           이루어진 문서 파일도 모두\n",
      "휴대용 정보통신기기               : 배율 및 대비 조절과                읽어주는 휴대용기기\n",
      "\n",
      "ㆍ대표적인 점자정보단말기            색상 변경 등 다양한 기능         ㆍ최근에는 인쇄물을 읽어주는\n",
      "- 브레일 한소네(한국)                                                           음성독서기도 제즈\n",
      "- Braille 40[6(뉴질랜드)            *ㆍ탁상용과 휴대용이 있음              SSA 제작\n",
      "\n",
      "시곽장애인과 함께 BOr7|\n",
      "\n",
      "확기기나 보조 프로그램\n",
      "장매인의 업무영역은 매우 넓\n",
      "\n",
      "취업자 구인구\n",
      "10만 7전명\n",
      "\n",
      "AN 고용\n",
      "^ 43.1%\n",
      "\n",
      "한국장애인고8공단 FP\n",
      "\n",
      "비장애인                       시각장애\n",
      "\n",
      "| 2021년 고용률 비교 |\n",
      "\n",
      "3. 함께 일하기                                                                            한국장애인고8공단 FP\n",
      "\n",
      "사업, 개인, 공공 서비스\n",
      "및 TIE\n",
      "\n",
      "활동실태조사\n",
      "\n",
      "출처 : 한국장애인고용공단 고용개발원 2021년 장애인경제\n",
      "\n",
      "년 —~ , >\n",
      "\n",
      "개\n",
      "\n",
      "개\n",
      "\n",
      "> a [님      a\n",
      "\n",
      "SU7t&HSOl\n",
      "\n",
      "사람들 읽다\n",
      "\n",
      "시각장애인이  악을 만나다\n",
      "J                 lL\n",
      "- sbepundbew\n",
      "\n",
      "3. 함께 일하7|                                                                            한국장애인고8공단 FP\n",
      "\n",
      "Sana 컴퓨터 제공                         상황, 면접, 작성*검토 시간 1.5배 연\n",
      "\n",
      "학7|7| 끼원사업\n",
      "\n",
      "학7|7| Nz\n",
      "\n",
      "점자정보단말기\n",
      "\n",
      "팍업7|구\n",
      "\n",
      "한국장애인고8공단 FP\n",
      "\n",
      "근로끼원인 Mei“ ME?\n",
      "\n",
      "!하여 안정적이고 끼|속적인 직업생활에 어려움을\n",
      "인을 지원하는 서비스\n",
      "\n",
      "=\n",
      "\n",
      "ev 년 년 vv 년 년 vv 년년 ue vv uo ou ue eu 0 0 ©\n",
      "\n",
      "적인 직업생활에\n",
      "\n",
      " 장애로 인해 안점적이고 NISMO! 찍업생활\n",
      "\n",
      "어려움을 겪는 SST! 근로자 또는\n",
      "공단 고용지원 Zee 결정 결과에 따라\n",
      "\n",
      "서비스가 필요 장매인 Seat\n",
      "/|각장애 지원 서비스\n",
      ". 함께 일하기                                                                                                     한국장애인고용공단\n",
      "근로끼원인의 sa\n",
      "\n",
      "장애인근로자가 사업주의\n",
      "공단에 근로지원인 서비스\n",
      "\n",
      "ㄴ\n",
      "\n",
      "~ 공단\n",
      "\n",
      "bees                       근로지원인을 모집\n",
      "vw SSNS        fairteterie\n",
      "\n",
      "근로지원인의 At\n",
      "\n",
      "EE  사업주           장애인근로자에\n",
      "\n",
      "인근로자의 업무지시를 받아, 장애인근로자가\n",
      "그       Oo                                   ’\n",
      "ore 근로지원인                수적 업무에 대한 근로지원\n",
      "\n",
      "3. 함께 일하7|                                                                            한국장야인고8공단 FL\n",
      "\n",
      "근로끼원인의 NAA! 재원\n",
      "\n",
      "조성된 7|금\n",
      "\n",
      "장애인근로까의 자부담\n",
      "\n",
      "근로끼원인의 임금은\n",
      "“잠애인고용쪽진 및 직업깨활법\"에 의해\n",
      "조성된 7|금과\n",
      "비스 제공           장애인근로까의 까부담으로 구성\n",
      "\n",
      "*매월 수행기관은 근로지원인 근무현황에 따른 사업비를\n",
      "공단에 신청하고, 근로지원인에게 임금을 지급\n",
      "\n",
      "A. 71억해주세요/                                                                                                                                   한국장애인고용공단 7?\n",
      "\n",
      "이름부터                 환경이 변하면\n",
      "이야기해 주세요            미리 얘기해주세요\n",
      "\n",
      "4. 7|억해주세요/                                                                                              한국장애인고용공단\n",
      "\n",
      "위지를 알려줄 때 구제적으로 알려주고\n",
      "함께 걸을 때는 지팡이 반대쪽에서\n",
      "aS 잡고 이동해 주세요\n",
      "\n",
      "A. 71억해주세요/                                                                                                                   한국장애인고용공단 +7\n",
      "\n",
      "> 아아이 아아아\n",
      "\n",
      "잠매인복지법 제40조\n",
      "| gg See HOO OS REACIg OBATALY\n",
      "SERA Seg Cie wet SSO OM\n",
      "SE UG ROIS ROE CECE\n",
      "\n",
      "ree\n",
      "95s\n",
      "\n",
      "4. 7|억해주세요/                                                                                              한국장애인고용공단 7\n",
      "\n",
      "인명피해\n",
      "\n",
      "(사맘+부삼)\n",
      "\n",
      "사망자\n",
      "\n",
      "출처 : 22. 09.19. ABS\n",
      "\n",
      "4. 7|1억해주세요/                                                                                                                                   한국장애인고용공단 ait\n",
      "\n",
      "Hayaagad AP                                                                                                                               =\n",
      "QHND 1588-1519                                                                                                                    한국장에인고용강단\n",
      "0폴전화 1586-1519\n",
      "\n",
      "한국장애인 Ban AP\n",
      "08008 1588-1619\n",
      "\n",
      "장애인 근로자의 대피계획 준비\n",
      "\n",
      "|   사업주의 대피계획                                             ua                             2단계, 대피 준비하기\n",
      "                                                                        ㆍ 비상 HIBS 사전 확인\n",
      "ㆍ 대피시설과 대피 장비 사용법\n",
      "\n",
      "숙지\n",
      "\n",
      ":대피계획에 따른 대피로 숙지\n",
      "\n",
      "4. 71억해주세요/                                                                       한국장야인고8공단 FL\n",
      "\n",
      "시곽장애인의 재난안전대피\n",
      "\n",
      "“HSS 키트에 여분의 흰 지팡이 준비\n",
      "“HAAS 사용하는 근로자의 경우, 비상용 키트에 보조견에 대한\n",
      "정보와 보조견 사료 준비\n",
      "\n",
      ":저시력 장애인 근로자는 안내 사인, 비상등, 비상 소명창치 SS\n",
      "\n",
      "통해 자신의 위치 파악\n",
      "Ss 시각장애인 SEAS 점자 ALES 이용해\n",
      "대피로 파악하거나 평소에 대피로 숙지\n",
      "“CHD 시 피난용 엘리베이터로 지정된 엘리베이터만 사용하며,\n",
      "사전에 위치를 파악 필요\n",
      "*피난용 엘리베이터가 없다면, 계단을 이용해 대피\n",
      "*안내 보행이 필요한 경우 대피지원인을 요청하고, 대피지원인에게\n",
      "사전에 시각장애인 안내방법 및 주의사항을 사전에 숙지시킴\n",
      "SOHO] 정도나 개인적 특성에 따라 저시력 장애인도 안내 보행 필요\n",
      "\n",
      "4. 71억해주세요/                                                                       한국장야인고8공단 FL\n",
      "\n",
      "시곽장애인의 재난안전대피\n",
      "\n",
      "주의사항 |\n",
      "\n",
      "*시각장애인 근로자의 보행속도에 맞춰 안내\n",
      "\n",
      "*시각장애인 근로자의 보행속도가 느려도\n",
      "끌어당기는 것은 자제\n",
      "\n",
      "*계단 이용이 어려울 경우, 방화구획 등\n",
      "\n",
      "대피공간으로 대피해 구조요청\n",
      "*대피지원인과 함께 정기적인 대피 연습 중\n",
      "\n",
      "A. 71억해주세요/                                                                                                                   한국장애인고용공단 +\n",
      "\n",
      "SOHNE ONS\n",
      "\n",
      "맹인-봉/\\-장님-소경\n",
      "\n",
      "5. 마무리                                                                                                                                                  한국장애인고용공단 +7\n",
      "\n",
      "시과장매인고\n",
      "\n",
      "사회적가치를 살현하는\n",
      "zl 8 $204 E04\n",
      "\n",
      "오들이 주요뉴스\n",
      "\n",
      "점]ㅁ스크 Paes  3s 제한\n",
      "\"289 -1000지' 환회 2:\n",
      "\n",
      "DER] EF 차, '내여차 휘발유\n",
      "SAME EOE 거의 없다\n",
      "\n",
      "피들리, 소매 GG FO! 거려\n",
      "계좌 개설 시작\n",
      "\n",
      "ㆍ\n",
      "사우디, 2 OFC OF 초대형 2) 살만\n",
      "국제송향 짓는다\n",
      "vel\n",
      "\n",
      "5. 마무리                                          한국장애인고8공단 FP\n",
      "\n",
      "2022년 M313] 장애인고용 콘텐즈 공모전 영상 분야 우수상\n",
      "\n",
      "r                         # /|각장애 AISISAIAFALIOHE 모습 # 보조공학717| NSIS\n",
      "KOO,\n",
      "\n",
      "# 근로지원인 서비스 소개 등\n",
      "\n",
      "https://www.youtube.com/watch?v=u9-EdLTfeEY (출처 : 한국장애인고용공단 유튜브)\n",
      "\n",
      "\n",
      "Text saved to preprocessed_OCR.txt\n"
     ]
    }
   ],
   "source": [
    "pdf_text_preprocessed = ocr_from_pdf(pages)\n",
    "print(pdf_text_preprocessed)\n",
    "\n",
    "txt_file_path = 'preprocessed_OCR.txt'\n",
    "save_text_to_file(pdf_text_preprocessed, txt_file_path)\n",
    "print(f\"Text saved to {txt_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The provided dictionary language (ko) does not exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spellchecker\\spellchecker.py:60\u001b[0m, in \u001b[0;36mSpellChecker.__init__\u001b[1;34m(self, language, local_dictionary, distance, tokenizer, case_sensitive)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     json_open \u001b[38;5;241m=\u001b[39m \u001b[43mpkgutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspellchecker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pkgutil.py:639\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(package, resource)\u001b[0m\n\u001b[0;32m    638\u001b[0m resource_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;241m*\u001b[39mparts)\n\u001b[1;32m--> 639\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1073\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\dm705\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\spellchecker\\\\resources\\\\ko.json.gz'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspellchecker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpellChecker\n\u001b[1;32m----> 3\u001b[0m spell \u001b[38;5;241m=\u001b[39m \u001b[43mSpellChecker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mko\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrect_spelling\u001b[39m(text):\n\u001b[0;32m      6\u001b[0m     corrected_text \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spellchecker\\spellchecker.py:63\u001b[0m, in \u001b[0;36mSpellChecker.__init__\u001b[1;34m(self, language, local_dictionary, distance, tokenizer, case_sensitive)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     62\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe provided dictionary language (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) does not exist!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m json_open:\n\u001b[0;32m     65\u001b[0m     lang_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(gzip\u001b[38;5;241m.\u001b[39mdecompress(json_open)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: The provided dictionary language (ko) does not exist!"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Requirements: `pip install pyspellchecker`\n",
    "\"\"\"\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker(language='ko')\n",
    "\n",
    "def correct_spelling(text):\n",
    "    corrected_text = []\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        corrected_word = spell.correction(word)\n",
    "        corrected_text.append(corrected_word)\n",
    "    return ' '.join(corrected_text)\n",
    "\n",
    "# 텍스트 추출 후 철자 교정\n",
    "# pdf_text = ocr_from_pdf(pages)\n",
    "corrected_text = correct_spelling(pdf_text_preprocessed)\n",
    "print(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.train.zip\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.train\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.test.zip\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.test\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.dev.zip\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.dev\n",
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : Hyunjoong Kim lovit@github\n",
      "    Repository : https://github.com/lovit/kowikitext\n",
      "    References :\n",
      "\n",
      "    한국어 위키피디아의 덤프 데이터를 바탕을 제작한 wikitext 형식의 텍스트 파일입니다.\n",
      "    학습 및 평가를 위하여 위키페이지 별로 train (99%), dev (0.5%), test (0.5%) 로 나뉘어져있습니다.\n",
      "\n",
      "\n",
      "    # License\n",
      "    CC-BY-SA 3.0 which kowiki dump dataset is licensed\n",
      "\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.train.zip\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.train\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.test.zip\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.test\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.dev.zip\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.dev\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SentencePair' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# KoWikiText 데이터에서 단어 추출\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m kowikitext\u001b[38;5;241m.\u001b[39mtrain:\n\u001b[1;32m---> 14\u001b[0m     words\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m())\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 단어 목록을 파일로 저장\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkorean_words.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SentencePair' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Requirements: `pip install korpora`\n",
    "\"\"\"\n",
    "\n",
    "from Korpora import Korpora\n",
    "\n",
    "# 사용할 데이터셋 다운로드\n",
    "Korpora.fetch('kowikitext')\n",
    "\n",
    "# 데이터 로드\n",
    "kowikitext = Korpora.load('kowikitext')\n",
    "\n",
    "# 단어 목록 추출\n",
    "words = set()\n",
    "\n",
    "# KoWikiText 데이터에서 단어 추출\n",
    "for text in kowikitext.train:\n",
    "    words.update(text.split())\n",
    "\n",
    "# 단어 목록을 파일로 저장\n",
    "with open('korean_words.txt', 'w', encoding='utf-8') as f:\n",
    "    for word in words:\n",
    "        f.write(f\"{word}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.train.zip\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.train\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.test.zip\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.test\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.dev.zip\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.dev\n",
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : Hyunjoong Kim lovit@github\n",
      "    Repository : https://github.com/lovit/kowikitext\n",
      "    References :\n",
      "\n",
      "    한국어 위키피디아의 덤프 데이터를 바탕을 제작한 wikitext 형식의 텍스트 파일입니다.\n",
      "    학습 및 평가를 위하여 위키페이지 별로 train (99%), dev (0.5%), test (0.5%) 로 나뉘어져있습니다.\n",
      "\n",
      "\n",
      "    # License\n",
      "    CC-BY-SA 3.0 which kowiki dump dataset is licensed\n",
      "\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.train.zip\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.train\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.test.zip\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.test\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.dev.zip\n",
      "[Korpora] Corpus `kowikitext` is already installed at C:\\Users\\dm705\\Korpora\\kowikitext\\kowikitext_20200920.dev\n"
     ]
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "\n",
    "# 사용할 데이터셋 다운로드\n",
    "Korpora.fetch('kowikitext')\n",
    "\n",
    "# 데이터 로드\n",
    "kowikitext = Korpora.load('kowikitext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 한글 단어만 추출하기 위한 정규식 패턴\n",
    "hangul_pattern = re.compile(r'[가-힣]+')\n",
    "\n",
    "# 단어 목록 추출\n",
    "words = set()\n",
    "\n",
    "# KoWikiText 데이터에서 단어 추출\n",
    "for sentence in kowikitext.train:\n",
    "    for word in sentence.text.split():\n",
    "        if hangul_pattern.fullmatch(word):\n",
    "            words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 4426308개의 한국어 단어가 추출되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 단어 목록을 파일로 저장\n",
    "with open('korean_words.txt', 'w', encoding='utf-8') as f:\n",
    "    for word in words:\n",
    "        f.write(f\"{word}\\n\")\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"총 {len(words)}개의 한국어 단어가 추출되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "# 한국어 단어 목록 파일 경로\n",
    "dictionary_path = 'korean_words.txt'\n",
    "index_path = 'korean_dictionary.gz'\n",
    "\n",
    "# 한국어 단어 목록을 불러와서 인덱스 파일 생성\n",
    "spell = SpellChecker(language=None)\n",
    "with open(dictionary_path, 'r', encoding='utf-8') as file:\n",
    "    words = file.read().splitlines()\n",
    "    spell.word_frequency.load_words(words)\n",
    "\n",
    "# 인덱스 파일로 저장\n",
    "spell.export(index_path, gzipped=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['장애인', '인식', '개선을', '위한', '방법은', '무엇인가요']\n",
      "장애인 인식 개선을 위한 방법은 무엇인가요\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "# 생성된 인덱스 파일 설정\n",
    "spell = SpellChecker(language=None, local_dictionary='korean_dictionary.gz')\n",
    "\n",
    "# 철자 교정 예제\n",
    "text = \"장애인 인식 개선을 위한 방법은 무엇인가요?\"\n",
    "words = text.split()\n",
    "corrected_words = [spell.correction(word) for word in words]\n",
    "print(corrected_words)\n",
    "corrected_text = ' '.join(corrected_words)\n",
    "print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3) pptx Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-pptx\n",
      "  Downloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
      "     -------------------------------------- 471.6/471.6 kB 9.8 MB/s eta 0:00:00\n",
      "Collecting lxml>=3.1.0\n",
      "  Downloading lxml-5.2.2-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "     ---------------------------------------- 3.8/3.8 MB 11.6 MB/s eta 0:00:00\n",
      "Collecting XlsxWriter>=0.5.7\n",
      "  Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "     -------------------------------------- 159.9/159.9 kB 9.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\jhuyk\\anaconda3\\lib\\site-packages (from python-pptx) (10.3.0)\n",
      "Installing collected packages: XlsxWriter, lxml, python-pptx\n",
      "Successfully installed XlsxWriter-3.2.0 lxml-5.2.2 python-pptx-0.6.23\n"
     ]
    }
   ],
   "source": [
    "!pip install python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to extract_text_[PPT] 직장 내 장애인 인식개선 교육 표준교안 PPT(국문)_수정.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Requirements: pip install python-pptx\n",
    "\"\"\"\n",
    "\n",
    "from pptx import Presentation\n",
    "import pandas as pd\n",
    "\n",
    "file_name = \"[PPT] 직장 내 장애인 인식개선 교육 표준교안 PPT(국문)_수정\"\n",
    "prs = Presentation(f\"dataset/{file_name}.pptx\")\n",
    "\n",
    "# def: extract text from slide\n",
    "def extract_text_from_slide(slide):\n",
    "    text = \"\"\n",
    "    for shape in slide.shapes:\n",
    "        if hasattr(shape, \"text_frame\") and shape.text_frame:\n",
    "            for paragraph in shape.text_frame.paragraphs:\n",
    "                for run in paragraph.runs:\n",
    "                    text += run.text + \" \"\n",
    "    return text.strip()\n",
    "\n",
    "# Extract Text from all slides\n",
    "all_slides_text = []\n",
    "for slide_num, slide in enumerate(prs.slides, start=1):\n",
    "    slide_content = {\n",
    "        \"Slide Number\": slide_num,\n",
    "        \"Text\": extract_text_from_slide(slide)\n",
    "    }\n",
    "    all_slides_text.append(slide_content)\n",
    "\n",
    "# convert the list to a DataFrame\n",
    "all_slides_text_df = pd.DataFrame(all_slides_text)\n",
    "\n",
    "csv_file_path = f\"extract_text_{file_name}.csv\"\n",
    "all_slides_text_df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"CSV file saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'장애인 업무의 한계를 없애다   상시  근로자  100,016 명  /  장애인  근로자  1,386 명 (1.54%)  * 2018.12 월 기준 장애물 없는 생활환경  (Barrier Free) 자체 인증 제도를 각 사업장에 도입  상담심리사를 상주시켜  직무갈등 ,  대인관계 등 고충을 해결  업무에 집중할 환경을 마련  장애인 고객의 입장에서  바라본   기술개발에도 적극 참여  장애인은   단순 업무만 해야 하나 ? ‘ 삼성전자 맞춤형 인재 ’ 로 성장하는데 있어서  비장애인과 장애인의 구분은 의미가 없다고 판단 , 직무교육을 거쳐 고용된 장애인은 각 사업장에서  전기 · 전자 ,  정보기술 ,  기계디자인 분야에서 근무 중 장애인고용 기업 사례 장애인 고용 전문가와 함께 다양한 장애인 고용 대책 마련'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = all_slides_text_df['Text'].iloc[4]\n",
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = \"t5-small\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name, legacy=False)\n",
    "\n",
    "# 입력 텍스트를 모델 입력 형식으로 변환\n",
    "input_text = f\"split sentences: {example_text}\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# 모델로 문장 생성\n",
    "outputs = model.generate(input_ids, max_new_tokens=200, num_beams=5, early_stopping=True)\n",
    "\n",
    "# 결과 디코딩 및 출력\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '                                                        '}]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The Korean tokenizer (\"spacy.ko.KoreanTokenizer\") requires [mecab-ko](https://bitbucket.org/eunjeon/mecab-ko/src/master/README.md), [mecab-ko-dic](https://bitbucket.org/eunjeon/mecab-ko-dic), and [natto-py](https://github.com/buruzaemon/natto-py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# spaCy 모델 로드\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblank\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mko\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m nlp\u001b[38;5;241m.\u001b[39madd_pipe(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentencizer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 주어진 텍스트\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\__init__.py:79\u001b[0m, in \u001b[0;36mblank\u001b[1;34m(name, vocab, config, meta)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# We should accept both dot notation and nested dict here for consistency\u001b[39;00m\n\u001b[0;32m     78\u001b[0m config \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mdot_to_dict(config)\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLangClass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:1855\u001b[0m, in \u001b[0;36mLanguage.from_config\u001b[1;34m(cls, config, vocab, disable, enable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[0;32m   1849\u001b[0m warn_if_jupyter_cupy()\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;66;03m# Note that we don't load vectors here, instead they get loaded explicitly\u001b[39;00m\n\u001b[0;32m   1852\u001b[0m \u001b[38;5;66;03m# inside stuff like the spacy train function. If we loaded them here,\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m \u001b[38;5;66;03m# then we would load them twice at runtime: once when we make from config,\u001b[39;00m\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;66;03m# and then again when we load from disk.\u001b[39;00m\n\u001b[1;32m-> 1855\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mlang_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_vectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m after_creation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1862\u001b[0m     nlp \u001b[38;5;241m=\u001b[39m after_creation(nlp)\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:220\u001b[0m, in \u001b[0;36mLanguage.__init__\u001b[1;34m(self, vocab, max_length, meta, create_tokenizer, create_vectors, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m     tokenizer_cfg \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlp\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m    219\u001b[0m     create_tokenizer \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mresolve(tokenizer_cfg)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_error_handler \u001b[38;5;241m=\u001b[39m raise_error\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\lang\\ko\\__init__.py:26\u001b[0m, in \u001b[0;36mcreate_tokenizer.<locals>.korean_tokenizer_factory\u001b[1;34m(nlp)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkorean_tokenizer_factory\u001b[39m(nlp):\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mKoreanTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\lang\\ko\\__init__.py:34\u001b[0m, in \u001b[0;36mKoreanTokenizer.__init__\u001b[1;34m(self, vocab)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, vocab: Vocab):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab \u001b[38;5;241m=\u001b[39m vocab\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mecab \u001b[38;5;241m=\u001b[39m \u001b[43mtry_mecab_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mecab_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\lang\\ko\\__init__.py:105\u001b[0m, in \u001b[0;36mtry_mecab_import\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MeCab\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe Korean tokenizer (\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspacy.ko.KoreanTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) requires \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[mecab-ko](https://bitbucket.org/eunjeon/mecab-ko/src/master/README.md), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[mecab-ko-dic](https://bitbucket.org/eunjeon/mecab-ko-dic), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand [natto-py](https://github.com/buruzaemon/natto-py)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: The Korean tokenizer (\"spacy.ko.KoreanTokenizer\") requires [mecab-ko](https://bitbucket.org/eunjeon/mecab-ko/src/master/README.md), [mecab-ko-dic](https://bitbucket.org/eunjeon/mecab-ko-dic), and [natto-py](https://github.com/buruzaemon/natto-py)"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# spaCy 모델 로드\n",
    "nlp = spacy.blank('ko')\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "# 주어진 텍스트\n",
    "text = '''장애인 업무의 한계를 없애다 상시 근로자 100,016 명 / 장애인 근로자 1,386 명 (1.54%) * 2018.12 월 기준 장애물 없는 생활환경 \n",
    "(Barrier Free) 자체 인증 제도를 각 사업장에 도입 상담심리사를 상주시켜 직무갈등 , 대인관계 등 고충을 해결 \n",
    "업무에 집중할 환경을 마련 장애인 고객의 입장에서 바라본 기술개발에도 적극 참여 장애인은 단순 업무만 해야 하나 ? \n",
    "‘ 삼성전자 맞춤형 인재 ’ 로 성장하는데 있어서 비장애인과 장애인의 구분은 의미가 없다고 판단 , 직무교육을 거쳐 고용된 장애인은 \n",
    "각 사업장에서 전기 · 전자 , 정보기술 , 기계디자인 분야에서 근무 중 장애인고용 기업 사례 장애인 고용 전문가와 함께 다양한 장애인 고용 대책 마련'''\n",
    "\n",
    "# 텍스트를 문장 단위로 분리\n",
    "doc = nlp(text)\n",
    "sentences = [sent.text.strip() + '.' for sent in doc.sents]\n",
    "\n",
    "# 결과 출력\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dm705\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "장애인 업무의 한계를 없애다   상시  근로자  100,016 명  /  장애인  근로자  1,386 명 (1.54%)  * 2018.12 월 기준 장애물 없는 생활환경  (Barrier Free) 자체 인증 제도를 각 사업장에 도입  상담심리사를 상주시켜  직무갈등 ,  대인관계 등 고충을 해결  업무에 집중할 환경을 마련  장애인 고객의 입장에서  바라본   기술개발에도 적극 참여  장애인은   단순 업무만 해야 하나 ?.\n",
      "‘ 삼성전자 맞춤형 인재 ’ 로 성장하는데 있어서  비장애인과 장애인의 구분은 의미가 없다고 판단 , 직무교육을 거쳐 고용된 장애인은 각 사업장에서  전기 · 전자 ,  정보기술 ,  기계디자인 분야에서 근무 중 장애인고용 기업 사례 장애인 고용 전문가와 함께 다양한 장애인 고용 대책 마련.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# 문장 단위로 분리\n",
    "sentences = sent_tokenize(example_text)\n",
    "\n",
    "# 결과 출력\n",
    "for sentence in sentences:\n",
    "    print(sentence + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name, legacy=False)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 주어진 텍스트\n",
    "text = (\n",
    "    \"장애인 업무의 한계를 없애다 상시 근로자 100,016 명 / 장애인 근로자 1,386 명 (1.54%) * 2018.12 월 기준 장애물 없는 생활환경 \"\n",
    "    \"(Barrier Free) 자체 인증 제도를 각 사업장에 도입 상담심리사를 상주시켜 직무갈등 , 대인관계 등 고충을 해결 \"\n",
    "    \"업무에 집중할 환경을 마련 장애인 고객의 입장에서 바라본 기술개발에도 적극 참여 장애인은 단순 업무만 해야 하나 ? \"\n",
    "    \"‘ 삼성전자 맞춤형 인재 ’ 로 성장하는데 있어서 비장애인과 장애인의 구분은 의미가 없다고 판단 , 직무교육을 거쳐 고용된 장애인은 \"\n",
    "    \"각 사업장에서 전기 · 전자 , 정보기술 , 기계디자인 분야에서 근무 중 장애인고용 기업 사례 장애인 고용 전문가와 함께 다양한 장애인 고용 대책 마련\"\n",
    ")\n",
    "\n",
    "# 입력 텍스트에 프롬프트 추가\n",
    "input_text = f\"split sentences: {text}\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# 모델로 문장 생성\n",
    "outputs = model.generate(input_ids, max_length=512, num_beams=5, early_stopping=True)\n",
    "\n",
    "# 결과 디코딩 및 출력\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "sentences = decoded_output.split('. ')\n",
    "for sentence in sentences:\n",
    "    print(sentence.strip() + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kss\n",
      "  Downloading kss-6.0.4.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.1/1.1 MB 35.7 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting emoji==1.2.0 (from kss)\n",
      "  Downloading emoji-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pecab (from kss)\n",
      "  Downloading pecab-1.0.8.tar.gz (26.4 MB)\n",
      "     ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 2.9/26.4 MB 61.7 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 5.3/26.4 MB 56.3 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 8.5/26.4 MB 60.9 MB/s eta 0:00:01\n",
      "     --------------- ----------------------- 10.7/26.4 MB 59.5 MB/s eta 0:00:01\n",
      "     --------------- ----------------------- 10.8/26.4 MB 43.7 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 11.1/26.4 MB 38.6 MB/s eta 0:00:01\n",
      "     ----------------- --------------------- 11.7/26.4 MB 32.7 MB/s eta 0:00:01\n",
      "     --------------------- ----------------- 14.5/26.4 MB 32.7 MB/s eta 0:00:01\n",
      "     ------------------------- ------------- 17.3/26.4 MB 32.7 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 20.1/26.4 MB 32.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 22.9/26.4 MB 59.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  25.7/26.4 MB 59.5 MB/s eta 0:00:01\n",
      "     --------------------------------------  26.4/26.4 MB 59.5 MB/s eta 0:00:01\n",
      "     --------------------------------------  26.4/26.4 MB 59.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 26.4/26.4 MB 38.4 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: networkx in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kss) (3.3)\n",
      "Collecting jamo (from kss)\n",
      "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting hangul-jamo (from kss)\n",
      "  Downloading hangul_jamo-1.0.1-py3-none-any.whl.metadata (899 bytes)\n",
      "Collecting tossi (from kss)\n",
      "  Downloading tossi-0.3.1.tar.gz (11 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting distance (from kss)\n",
      "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
      "     ---------------------------------------- 0.0/180.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 180.3/180.3 kB ? eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pyyaml==6.0 (from kss)\n",
      "  Downloading PyYAML-6.0-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting unidecode (from kss)\n",
      "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cmudict (from kss)\n",
      "  Downloading cmudict-1.0.26-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting koparadigm (from kss)\n",
      "  Downloading koparadigm-0.10.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting kollocate (from kss)\n",
      "  Downloading kollocate-0.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting bs4 (from kss)\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: numpy in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kss) (1.26.4)\n",
      "Collecting pytest (from kss)\n",
      "  Downloading pytest-8.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kss) (1.13.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bs4->kss) (4.12.3)\n",
      "Requirement already satisfied: importlib-metadata>=5 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cmudict->kss) (7.1.0)\n",
      "Requirement already satisfied: importlib-resources>=5 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cmudict->kss) (6.4.0)\n",
      "Collecting whoosh (from kollocate->kss)\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting xlrd==1.2.0 (from koparadigm->kss)\n",
      "  Downloading xlrd-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pecab->kss) (16.1.0)\n",
      "Requirement already satisfied: regex in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pecab->kss) (2024.5.15)\n",
      "Collecting iniconfig (from pytest->kss)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dm705\\appdata\\roaming\\python\\python311\\site-packages (from pytest->kss) (24.1)\n",
      "Collecting pluggy<2.0,>=1.5 (from pytest->kss)\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dm705\\appdata\\roaming\\python\\python311\\site-packages (from pytest->kss) (0.4.6)\n",
      "Collecting bidict (from tossi->kss)\n",
      "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: six in c:\\users\\dm705\\appdata\\roaming\\python\\python311\\site-packages (from tossi->kss) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib-metadata>=5->cmudict->kss) (3.19.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->bs4->kss) (2.5)\n",
      "Downloading emoji-1.2.0-py3-none-any.whl (131 kB)\n",
      "   ---------------------------------------- 0.0/131.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 131.3/131.3 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0-cp311-cp311-win_amd64.whl (143 kB)\n",
      "   ---------------------------------------- 0.0/143.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 143.2/143.2 kB ? eta 0:00:00\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading cmudict-1.0.26-py3-none-any.whl (939 kB)\n",
      "   ---------------------------------------- 0.0/939.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 939.4/939.4 kB 30.0 MB/s eta 0:00:00\n",
      "Downloading hangul_jamo-1.0.1-py3-none-any.whl (4.4 kB)\n",
      "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
      "Downloading kollocate-0.0.2-py3-none-any.whl (72.2 MB)\n",
      "   ---------------------------------------- 0.0/72.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 2.8/72.2 MB 61.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 5.5/72.2 MB 59.2 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 8.2/72.2 MB 58.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 10.9/72.2 MB 59.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 13.7/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 16.5/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 19.3/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 21.1/72.2 MB 54.4 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 21.2/72.2 MB 43.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 21.2/72.2 MB 36.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 21.3/72.2 MB 31.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 21.4/72.2 MB 27.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 21.7/72.2 MB 25.2 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 22.7/72.2 MB 23.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 25.5/72.2 MB 23.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 28.2/72.2 MB 23.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 31.0/72.2 MB 23.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 31.9/72.2 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 32.6/72.2 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 33.5/72.2 MB 38.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 36.0/72.2 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 38.6/72.2 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 41.2/72.2 MB 36.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 43.8/72.2 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 46.6/72.2 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 49.2/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 51.9/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 54.7/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 57.5/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 60.3/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 63.0/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 65.8/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 68.5/72.2 MB 59.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  71.2/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  72.2/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  72.2/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  72.2/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  72.2/72.2 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 72.2/72.2 MB 27.3 MB/s eta 0:00:00\n",
      "Downloading koparadigm-0.10.0-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 1.2/1.6 MB 71.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.2/1.6 MB 19.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.3/1.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.4/1.6 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.6/1.6 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 6.4 MB/s eta 0:00:00\n",
      "Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 103.3/103.3 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading pytest-8.2.2-py3-none-any.whl (339 kB)\n",
      "   ---------------------------------------- 0.0/339.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 339.9/339.9 kB 22.0 MB/s eta 0:00:00\n",
      "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "   ---------------------------------------- 0.0/235.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 235.5/235.5 kB 14.1 MB/s eta 0:00:00\n",
      "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "   ---------------------------------------- 0.0/468.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 468.8/468.8 kB 28.7 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: kss, distance, pecab, tossi\n",
      "  Building wheel for kss (pyproject.toml): started\n",
      "  Building wheel for kss (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for kss: filename=kss-6.0.4-py3-none-any.whl size=1089401 sha256=7353f4621e5feac0ef8e51e28d1d3285d6bba7967009c26b8083893e06ec9a3c\n",
      "  Stored in directory: c:\\users\\dm705\\appdata\\local\\pip\\cache\\wheels\\86\\c9\\5f\\69b8fe9751eefbb5d087932ddf58d0f121b8e545335af7fe4e\n",
      "  Building wheel for distance (pyproject.toml): started\n",
      "  Building wheel for distance (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16280 sha256=bf794e757ae0fc6299576640b849b4b892f5d69097715283da7936e01081a0ba\n",
      "  Stored in directory: c:\\users\\dm705\\appdata\\local\\pip\\cache\\wheels\\fb\\cd\\9c\\3ab5d666e3bcacc58900b10959edd3816cc9557c7337986322\n",
      "  Building wheel for pecab (pyproject.toml): started\n",
      "  Building wheel for pecab (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pecab: filename=pecab-1.0.8-py3-none-any.whl size=26646700 sha256=9dd8326752f6ddda01af9500170843a528032bc8f5d790020937f1d082bc0633\n",
      "  Stored in directory: c:\\users\\dm705\\appdata\\local\\pip\\cache\\wheels\\c9\\0d\\97\\ca2bb361e44a80f4c63efe6f6438ff903fd1ab5640eedabc1b\n",
      "  Building wheel for tossi (pyproject.toml): started\n",
      "  Building wheel for tossi (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for tossi: filename=tossi-0.3.1-py3-none-any.whl size=12138 sha256=4ccd4a1165a7a323af9221c306782963e29a2db6a6a70a36c4826ccc67dba66b\n",
      "  Stored in directory: c:\\users\\dm705\\appdata\\local\\pip\\cache\\wheels\\36\\1a\\7e\\0b78039c20678a6682f03cca4295efaa5fb55a3d10d7e9837a\n",
      "Successfully built kss distance pecab tossi\n",
      "Installing collected packages: whoosh, jamo, hangul-jamo, emoji, distance, xlrd, unidecode, pyyaml, pluggy, kollocate, iniconfig, bidict, tossi, pytest, koparadigm, cmudict, bs4, pecab, kss\n",
      "  Attempting uninstall: emoji\n",
      "    Found existing installation: emoji 2.12.1\n",
      "    Uninstalling emoji-2.12.1:\n",
      "      Successfully uninstalled emoji-2.12.1\n",
      "  Attempting uninstall: xlrd\n",
      "    Found existing installation: xlrd 2.0.1\n",
      "    Uninstalling xlrd-2.0.1:\n",
      "      Successfully uninstalled xlrd-2.0.1\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "Successfully installed bidict-0.23.1 bs4-0.0.2 cmudict-1.0.26 distance-0.1.3 emoji-1.2.0 hangul-jamo-1.0.1 iniconfig-2.0.0 jamo-0.4.1 kollocate-0.0.2 koparadigm-0.10.0 kss-6.0.4 pecab-1.0.8 pluggy-1.5.0 pytest-8.2.2 pyyaml-6.0 tossi-0.3.1 unidecode-1.3.8 whoosh-2.7.4 xlrd-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\dm705\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~aml'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kss import Kss\n",
    "\n",
    "split_sentences = Kss(\"split_sentences\")\n",
    "result = split_sentences(example_text)\n",
    "len(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kiwipiepy in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: kiwipiepy-model<0.18,>=0.17 in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kiwipiepy) (0.17.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kiwipiepy) (1.26.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dm705\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kiwipiepy) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\dm705\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->kiwipiepy) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kiwipiepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(text='장애인 업무의 한계를 없애다   상시  근로자  100,016 명  /  장애인  근로자  1,386 명 (1.54%)  * 2018.12 월 기준 장애물 없는 생활환경  (Barrier Free) 자체 인증 제도를 각 사업장에 도입  상담심리사를 상주시켜  직무갈등 ,  대인관계 등 고충을 해결  업무에 집중할 환경을 마련  장애인 고객의 입장에서  바라본   기술개발에도 적극 참여  장애인은   단순 업무만 해야 하나 ? ‘ 삼성전자 맞춤형 인재 ’', start=0, end=255, tokens=None, subs=[]),\n",
       " Sentence(text='로 성장하는데 있어서  비장애인과 장애인의 구분은 의미가 없다고 판단 , 직무교육을 거쳐 고용된 장애인은 각 사업장에서  전기 · 전자 ,  정보기술 ,  기계디자인 분야에서 근무 중 장애인고용 기업 사례 장애인 고용 전문가와 함께 다양한 장애인 고용 대책 마련', start=256, end=402, tokens=None, subs=[])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "\n",
    "kiwi = Kiwi()\n",
    "kiwi.split_into_sents(example_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
